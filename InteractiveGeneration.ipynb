{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Complete.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import time\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch as pt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from transformers import GPT2ForSequenceClassification, ReformerModelWithLMHead, get_linear_schedule_with_warmup\n",
    "from pytorch_transformers import GPT2Tokenizer\n",
    "from Learning import *\n",
    "dev = \"cuda\" if pt.cuda.is_available() else \"cpu\"\n",
    "device = pt.device(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cats, cats_sing, phrases = Listset().load()  # Import word lists dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([317, 1351, 286, 2835, 15921, 25, 22514, 11, 48389, 11, 279, 4127, 11],\n",
       " [317, 1351, 286, 2835, 15921, 25, 22514, 11],\n",
       " [48389, 11, 279, 4127, 11])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"A list of round fruits: apples, oranges, pears,\"), \\\n",
    "    tokenizer.encode(\"A list of round fruits: apples,\"), \\\n",
    "    tokenizer.encode(\"oranges, pears,\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "   ###   Options   ###\n",
    "\n",
    "model_name = \"ernst_one\"             # First, use a mean pooling of the claim and chained evidence\n",
    "test_set_frac = 0.25                 # Fraction of samples to keep as separate test set  (list sets)\n",
    "sample_test_n = 25                   # Number of randomly generated prompts for each sample when testing model\n",
    "log_period_batches = 25              # Batches per iteration\n",
    "learning_rate = 2e-5                 # Adam learning rate (default is 5e-5, sentiment classification example had 2e-5)\n",
    "adam_epsilon = 1e-8                  # Adam epsilon (default is 1e-8)\n",
    "n_sched_warmup = 0                   # Linear scheduler for optimizer number of warmup steps\n",
    "batch_size = bsz = 8                 # Samples per batch\n",
    "N_train_batches = int(1e7 / bsz)     # Total number of batches to show model\n",
    "min_nw, max_nw = 0.17, 0.8           # Minimum and maximum fraction of list to keep when truncating\n",
    "max_listlen = 20                     # Maximum number of words in the list when creating a prompt (at least prior to * max_nw)\n",
    "lidstone_e = 0.0                     # Smoothing for possible words/subwords which are not in the missing list words set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lprompts_encoded = [(tokenizer.encode(prompt), \"types of\" in prompt) for prompt in lprompts]\n",
    "cats_e = [[tokenizer.encode(c + ': ') for c in cs] for cs in cats]\n",
    "cats_sing_e = [[tokenizer.encode(c + ': ') for c in cs] for cs in cats_sing]\n",
    "phrases_e = [[tokenizer.encode(p + ', ') for p in ps] for ps in phrases]\n",
    "N_tokens = len(tokenizer)\n",
    "N_wordlists = len(cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a fixed test set and save to disk, using nw_draw = 15. This function defines the next list token prediction problem\n",
    "def gen_truncated_list(prmt, p):  # prmt = prompt tokens, p = list phrases tokens list\n",
    "    tkzs, sent, tkix = [], [], 0\n",
    "    incl_words = np.random.choice(len(p), min(max_listlen, len(p)), replace=False)\n",
    "    for phz_i in incl_words:\n",
    "        phz_enc = p[phz_i]\n",
    "        tkzs.append((tkix, phz_enc))\n",
    "        tkix += len(phz_enc)\n",
    "        sent += phz_enc\n",
    "    missing_w = [p[i] for i in range(len(p)) if i not in incl_words]\n",
    "    trunc_ix = np.random.randint(round(tkix * min_nw), round(tkix * max_nw))\n",
    "    trunc_n = min([(trunc_ix - ix) for (ix, enc) in tkzs if ix <= trunc_ix])  # N. end phrase tokens\n",
    "    missing_w += [enc for (ix, enc) in tkzs if ix >= (trunc_ix - trunc_n)]\n",
    "    missing_matches = missing_w\n",
    "    if trunc_n > 0:\n",
    "        phr_start = trunc_ix - trunc_n\n",
    "        partial_phr = sent[phr_start:trunc_ix]\n",
    "        missing_matches = [enc for enc in missing_w if enc[:trunc_n] == partial_phr]\n",
    "    next_tokens = [enc[trunc_n] for enc in missing_matches]\n",
    "    norm = len(next_tokens) * (1.0 + lidstone_e)\n",
    "    tunit, y_ = 1 / norm, np.tile(lidstone_e / N_tokens, N_tokens)\n",
    "    for token in next_tokens: y_[token] += tunit\n",
    "    return np.hstack([prmt, sent[:trunc_ix]]), y_\n",
    "def gen_samples_uniform(xcp, xcs, xp, nw, verbose=False):  # Weight testing samples (word lists) uniformly\n",
    "    xs, ys, sqlens, j = [], [], [], 0\n",
    "    for i in range(len(xcp)):\n",
    "        x, y, sqlen = [], [], []\n",
    "        cp, cs, p = xcp[i], xcs[i], xp[i]\n",
    "        for m in range(nw):\n",
    "            prmt, typesof = lprompts_encoded[np.random.randint(len(lprompts_encoded))]\n",
    "            cat_ix = np.random.randint(len(cp))\n",
    "            x_, y_ = gen_truncated_list(np.hstack([prmt, cp[cat_ix] if typesof else cs[cat_ix]]), p)\n",
    "            x.append(x_)\n",
    "            y.append(y_)\n",
    "            sqlen.append(len(x_))\n",
    "            j += 1\n",
    "            if verbose and j % 100 == 0:\n",
    "                sys_print(\"\\rDone: \" + str(j))\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "        sqlens.append(sqlen)\n",
    "    if verbose: sys_print(\"\\rDone: \" + str(j) + \", finished!\\n\")\n",
    "    return xs, ys, sqlens\n",
    "def gen_samples(xcp, xcs, xp, n):  # Maximise training batch diversity by randomly sampling the word lists\n",
    "    xs, ys, sqlens, j = [], [], [], 0\n",
    "    n_sets = len(xcp)\n",
    "    for m in range(n):\n",
    "        i = np.random.randint(n_sets)\n",
    "        cp, cs, p = xcp[i], xcs[i], xp[i]\n",
    "        prmt, typesof = lprompts_encoded[np.random.randint(len(lprompts_encoded))]\n",
    "        cat_ix = np.random.randint(len(cp))\n",
    "        x_, y_ = gen_truncated_list(np.hstack([prmt, cp[cat_ix] if typesof else cs[cat_ix]]), p)\n",
    "        xs.append(x_)\n",
    "        ys.append(y_)\n",
    "        sqlens.append(len(x_))\n",
    "    return xs, ys, sqlens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Done: 50, finished!\n"
     ]
    }
   ],
   "source": [
    "N_test = int(test_set_frac * N_wordlists)\n",
    "N_train = N_wordlists - N_test\n",
    "# test_idx = np.random.choice(N_wordlists, N_test, replace=False)\n",
    "test_idx = np.array([3, 7])\n",
    "cats_e_test, cats_sing_e_test = [cats_e[i] for i in test_idx], [cats_sing_e[i] for i in test_idx]\n",
    "phrases_e_test = [phrases_e[i] for i in test_idx]\n",
    "train_idx = [i for i in range(N_wordlists) if i not in test_idx]\n",
    "cats_e_train, cats_sing_e_train = [cats_e[i] for i in train_idx], [cats_sing_e[i] for i in train_idx]\n",
    "phrases_e_train = [phrases_e[i] for i in train_idx]\n",
    "test_cats = [cats[i][0] for i in test_idx]\n",
    "test_xs, test_ys, test_sqlens = gen_samples_uniform(cats_e_test, cats_sing_e_test, phrases_e_test, sample_test_n, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_ld((test_xs, test_ys, test_sqlens), \"test.data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_xs, test_ys, test_sqlens = load_ld(\"test.data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define next batch function\n",
    "max_len = 128\n",
    "def adapt_form(xs, ys, sqlens):\n",
    "    if max(sqlens) > max_len:\n",
    "        print(max(sqlens))\n",
    "#     max_len = 128#max(sqlens)\n",
    "    xs = pt.tensor(np.vstack([np.pad(x, (0, max_len - len(x)), constant_values=50256) for x in xs])).to(device)\n",
    "    ys = pt.tensor(np.vstack(ys)).to(device)#.cpu()\n",
    "    sqlens = pt.tensor(np.asarray(sqlens)).to(device)#.cpu()\n",
    "    return xs, ys, sqlens\n",
    "def next_batch(sz):\n",
    "    global cats_e_train, cats_sing_e_train, phrases_e_train\n",
    "    xs, ys, sqlens = gen_samples(cats_e_train, cats_sing_e_train, phrases_e_train, sz)\n",
    "    return adapt_form(xs, ys, sqlens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2-large and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2 loaded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "959"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(gc.collect())\n",
    "create_folder(\"models\")\n",
    "create_folder(\"models/pretrained\")\n",
    "create_folder(\"models/pretrained/GPT2SeqClas\")\n",
    "model = GPT2ForSequenceClassification.from_pretrained('gpt2-large',\n",
    "    output_hidden_states=True, output_attentions=True, \n",
    "    cache_dir=\"models/pretrained/GPT2SeqClas\")\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "model.config.pad_token_id = model.config.eos_token_id\n",
    "n_embd = model.config.n_embd\n",
    "# model = nn.parallel.DistributedDataParallel(\n",
    "model = nn.DataParallel(\n",
    "    model, device_ids=list(range(pt.cuda.device_count()))).to(device) if dev != \"cpu\" else model.cpu()\n",
    "print(\"GPT2 loaded\")\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "llayer = nn.Linear(n_embd, len(tokenizer), bias=False)#.cpu()\n",
    "nn.init.xavier_uniform_(llayer.weight)\n",
    "llayer = nn.DataParallel(llayer, device_ids=list(range(pt.cuda.device_count()))).to(device)\n",
    "# llayer = nn.parallel.DistributedDataParallel(llayer, device_ids=list(range(pt.cuda.device_count()))).to(device)\n",
    "# softmax = nn.Softmax()\n",
    "bcewl_loss = nn.BCEWithLogitsLoss()#.cpu()\n",
    "bcewl_loss = nn.DataParallel(bcewl_loss, device_ids=list(range(pt.cuda.device_count()))).to(device)\n",
    "# bcewl_loss = nn.parallel.DistributedDataParallel(bcewl_loss, device_ids=list(range(pt.cuda.device_count()))).to(device)\n",
    "# nll_loss = nn.NLLLoss()\n",
    "# kl_loss = nn.KLDivLoss()\n",
    "optimizer = pt.optim.AdamW(model.parameters(), lr=learning_rate, eps=adam_epsilon)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=n_sched_warmup, num_training_steps=N_train_batches)\n",
    "def sequence_mask(lengths, maxlen=None, dtype=pt.int):\n",
    "    if maxlen is None:\n",
    "        maxlen = lengths.max()\n",
    "    row_vector = pt.arange(0, maxlen, 1).to(device)\n",
    "    matrix = pt.unsqueeze(lengths, dim=-1)\n",
    "    mask = row_vector < matrix\n",
    "\n",
    "    mask = mask.type(dtype)\n",
    "    return mask\n",
    "def train_step():\n",
    "    global model, llayer, bcewl_loss, optimizer, scheduler\n",
    "    x_batch, y_batch, sqlens_batch = next_batch(batch_size)\n",
    "#     x_batch = x_batch.to(device)\n",
    "#     y_batch = y_batch.to(device)#.cpu()\n",
    "#     sqlens_batch = sqlens_batch.to(device)#.cpu()\n",
    "    \n",
    "    model.zero_grad()\n",
    "    mask = sequence_mask(sqlens_batch, max_len)\n",
    "    print(x_batch.shape, mask.shape)\n",
    "    outputs = model(x_batch.long(), attention_mask=mask)\n",
    "    out_idx = pt.unsqueeze(pt.unsqueeze(sqlens_batch - 1, 1).repeat((1, n_embd)), 1).type(pt.int64)\n",
    "    outs = pt.gather(outputs[2][-1].to(device), 1, out_idx).squeeze(1)\n",
    "#     outs = pt.gather(outputs[2][-1].cpu(), 1, out_idx).squeeze(1)\n",
    "    logits = llayer(outs)\n",
    "    \n",
    "#     logsofts = pt.log(softmax(logits))\n",
    "    loss = bcewl_loss(logits, y_batch.float()).to(device)#.cpu()\n",
    "    loss = loss.mean()\n",
    "    correct = pt.mean((y_batch[pt.arange(batch_size), pt.argmax(logits, axis=1)] > (lidstone_e / N_tokens)).float())\n",
    "    loss_, correct_ = loss.detach().cpu().numpy(), correct.detach().cpu().numpy()\n",
    "    \n",
    "    loss.backward()\n",
    "    nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    return loss_, correct_\n",
    "\n",
    "def inference(x, sqlens):\n",
    "    global model, llayer\n",
    "\n",
    "    x, sqlens = x.to(device), sqlens.to(device)#.cpu()\n",
    "    mask = sequence_mask(sqlens, max_len)\n",
    "    outputs = model(x.long(), attention_mask=mask)\n",
    "    out_idx = pt.unsqueeze(pt.unsqueeze(sqlens - 1, 1).repeat((1, n_embd)), 1).type(pt.int64)\n",
    "    outs = pt.gather(outputs[2][-1].to(device), 1, out_idx).squeeze(1)\n",
    "#     outs = pt.gather(outputs[2][-1].cpu(), 1, out_idx).squeeze(1)\n",
    "    logits = llayer(outs)\n",
    "    return logits\n",
    "def eval_test(x, y, sqlens):\n",
    "    global bcewl_loss\n",
    "\n",
    "    with pt.no_grad():\n",
    "        logits = inference(x, sqlens)\n",
    "        loss = bcewl_loss(logits, y.float()).to(device)#.cpu()\n",
    "        loss = loss.mean()\n",
    "        correct = pt.mean((y[pt.arange(x.shape[0]), pt.argmax(logits, axis=1)] > (lidstone_e / N_tokens)).float())\n",
    "        loss_, correct_ = loss.detach().cpu().numpy(), correct.detach().cpu().numpy()\n",
    "    return loss_, correct_\n",
    "\n",
    "# top_next = [self.tokenizer.decode(i.item()).strip() for i in probs.topk(k)[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_i = 0\n",
    "best_acc, best_loss = 0, np.inf\n",
    "best_acc_idx = -1\n",
    "create_folder(\"models\")\n",
    "create_folder(\"model_logs\")\n",
    "create_folder(\"models/\" + model_name)\n",
    "graphs_folder = \"graphs\"\n",
    "create_folder(graphs_folder)\n",
    "train_loss, train_accuracy, test_loss, test_accuracy = [], [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_training(verbose=True):\n",
    "    global model, batch_i, best_acc, best_loss, best_acc_idx, train_loss, train_accuracy, test_loss, test_accuracy\n",
    "    \n",
    "    model.train()\n",
    "    iter_loss, iter_accuracy, b_no_inp = [], [], 0\n",
    "    while batch_i < N_train_batches:\n",
    "        batch_i += 1\n",
    "        gc.collect()\n",
    "        if dev != \"cpu\": pt.cuda.empty_cache()\n",
    "        b_loss, b_accuracy = train_step()\n",
    "        if verbose:\n",
    "            sys_print('\\rLoss, accuracy: ' + str(np.mean(b_loss)) + ', ' + str(np.mean(b_accuracy)) + \\\n",
    "                      ' @ batch '+ str(batch_i) + ' (' + str(batch_i * batch_size) + ' samples) complete.                  ')\n",
    "        iter_loss.append(b_loss)\n",
    "        iter_accuracy.append(b_accuracy)\n",
    "        \n",
    "        if (batch_i - 1) % log_period_batches == 0:  # Test on test set\n",
    "            model.eval()\n",
    "            loss, accuracy = [], []\n",
    "            for i in range(N_test):\n",
    "                test_X, test_Y, test_Sqlens = adapt_form(test_xs[i], test_ys[i], test_sqlens[i])\n",
    "                feed_batches = [range(len(test_X))[i * bsz:(i + 1) * bsz] for i in range((len(test_X) // bsz) + 1)]\n",
    "                if dev != \"cpu\": pt.cuda.empty_cache()\n",
    "                ls, cs = zip(*[eval_test(test_X[inds], test_Y[inds], test_Sqlens[inds]) for inds in feed_batches])\n",
    "                loss.append(np.mean(ls))\n",
    "                accuracy.append(np.mean(cs))\n",
    "                print('\\n' + test_cats[i] + ': ' + str(loss[-1]) + ', ' + str(accuracy[-1]))\n",
    "            \n",
    "            test_l, test_a = np.mean(loss), np.mean(accuracy)\n",
    "            test_loss.append(test_l)\n",
    "            test_accuracy.append(test_a)\n",
    "            train_l, train_a = np.mean(iter_loss), np.mean(iter_accuracy)\n",
    "            train_loss.append(train_l)\n",
    "            train_accuracy.append(train_a)\n",
    "            iter_loss, iter_accuracy = [], []\n",
    "            \n",
    "            val_a = 0\n",
    "            if test_a > best_acc:      # Save best accuracy model\n",
    "                best_acc = test_a\n",
    "                best_loss = test_l\n",
    "                best_acc_idx = batch_i // log_period_batches\n",
    "                pt.save({\"model\": model.state_dict(),\n",
    "                         \"llayer\": llayer.state_dict(),\n",
    "#                          \"softrmax\": softrmax.state_dict(),\n",
    "                         \"bcewl_loss\": bcewl_loss.state_dict(),\n",
    "#                          \"nll_loss\": nll_loss.state_dict(),\n",
    "#                          \"kl_loss\": kl_loss.state_dict(),\n",
    "                         \"optimizer\": optimizer.state_dict(),\n",
    "                         \"scheduler\": scheduler.state_dict(),\n",
    "                         }, \"./models/\" + model_name + '/' + model_name)\n",
    "                b_no_inp = 0\n",
    "            else:\n",
    "                b_no_inp += log_period_batches\n",
    "                \n",
    "            if verbose:\n",
    "                clear_output()\n",
    "                print(\"Batch\", batch_i, ':', train_a, test_a, \"loss:\", train_l, test_l, \\\n",
    "                      \"Best:\", best_acc, best_loss, 'idx:', best_acc_idx)\n",
    "                fig = plt.figure()\n",
    "                fig.set_size_inches(16, 5)\n",
    "                g = fig.add_subplot(1,2,1)\n",
    "                g.grid()\n",
    "                g.plot(train_accuracy, label='train acc')\n",
    "                g.plot(test_accuracy, label='test acc')\n",
    "                g.legend(loc='lower right')\n",
    "#                 g.axhline(y=0.714, ls='--', color='grey')\n",
    "\n",
    "                g = fig.add_subplot(1,2,2)\n",
    "                g.grid()\n",
    "                g.plot(train_loss, label='train loss')\n",
    "                g.plot(test_loss, label='test loss')\n",
    "                g.legend(loc='upper right')\n",
    "\n",
    "                save_ld((train_accuracy, test_accuracy, train_loss, test_loss),\n",
    "                        \"model_logs/\" + model_name + '_log_latest', pad=False)\n",
    "                plt.savefig(graphs_folder + '/' + model_name + \"_curve_latest\" + '.pdf', format='pdf')\n",
    "                plt.show()\n",
    "            model.train()\n",
    "    return best_acc, best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 : 0.0 0.0 loss: 0.6975563 0.6964075 Best: 0 inf idx: -1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 128]) torch.Size([8, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 246.00 MiB (GPU 0; 15.78 GiB total capacity; 14.10 GiB already allocated; 79.75 MiB free; 14.18 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-5ff61b84ca1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0miterate_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-30c03d2258f6>\u001b[0m in \u001b[0;36miterate_training\u001b[0;34m(verbose)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdev\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mb_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             sys_print('\\rLoss, accuracy: ' + str(np.mean(b_loss)) + ', ' + str(np.mean(b_accuracy)) + \\\n",
      "\u001b[0;32m<ipython-input-13-8a264503271b>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mloss_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 246.00 MiB (GPU 0; 15.78 GiB total capacity; 14.10 GiB already allocated; 79.75 MiB free; 14.18 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "print(gc.collect())\n",
    "iterate_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to load a model\n",
    "# gc.collect()\n",
    "# checkpoint = pt.load(\"./models/\" + model_name + '/' + model_name)\n",
    "# model.load_state_dict(checkpoint['model'])\n",
    "# llayer.load_state_dict(checkpoint['llayer'])\n",
    "# bcewl_loss.load_state_dict(checkpoint['bcewl_loss'])\n",
    "# optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "# scheduler.load_state_dict(checkpoint['scheduler'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_top_p_filtering(logits, top_k=0, top_p=0.0, filter_value=-float('Inf')):\n",
    "    \"\"\" Filter a distribution of logits using top-k and/or nucleus (top-p) filtering\n",
    "        Args:\n",
    "            logits: logits distribution shape (vocabulary size)\n",
    "            top_k >0: keep only top k tokens with highest probability (top-k filtering).\n",
    "            top_p >0.0: keep the top tokens with cumulative probability >= top_p (nucleus filtering).\n",
    "                Nucleus filtering is described in Holtzman et al. (http://arxiv.org/abs/1904.09751)\n",
    "    \"\"\"\n",
    "    assert logits.dim() == 1  # batch size 1 for now - could be updated for more but the code would be less clear\n",
    "    top_k = min(top_k, logits.size(-1))  # Safety check\n",
    "    if top_k > 0:\n",
    "        # Remove all tokens with a probability less than the last token of the top-k\n",
    "        indices_to_remove = logits < pt.topk(logits, top_k)[0][..., -1, None]\n",
    "        logits[indices_to_remove] = filter_value\n",
    "\n",
    "    if top_p > 0.0:\n",
    "        sorted_logits, sorted_indices = pt.sort(logits, descending=True)\n",
    "        cumulative_probs = pt.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n",
    "\n",
    "        # Remove tokens with cumulative probability above the threshold\n",
    "        sorted_indices_to_remove = cumulative_probs > top_p\n",
    "        # Shift the indices to the right to keep also the first token above the threshold\n",
    "        sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n",
    "        sorted_indices_to_remove[..., 0] = 0\n",
    "\n",
    "        indices_to_remove = sorted_indices[sorted_indices_to_remove]\n",
    "        logits[indices_to_remove] = filter_value\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_next_token(sent, top_k=-1, top_p=0.9, temperature=1.0):\n",
    "    global model\n",
    "    model.eval()\n",
    "    tokens = tokenizer.encode(sent)\n",
    "    x = pt.tensor([tokens])\n",
    "    if dev != \"cpu\": pt.cuda.empty_cache()\n",
    "    logits = inference(x, pt.tensor([len(tokens)]))[0]\n",
    "    logits /= temperature\n",
    "    logits = top_k_top_p_filtering(logits, top_k=top_k, top_p=top_p)\n",
    "    probs = F.softmax(logits, dim=0)\n",
    "    token = pt.multinomial(probs, 1).numpy()[0]\n",
    "    tokens += [token]\n",
    "    sent = tokenizer.decode(tokens)\n",
    "    print(sent)\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentence = \"A list of types of drink: coffee, water, tea, coke, lemonade, milkshake,\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentence = append_next_token(input_sentence, top_k=-1, top_p=0.9, temperature=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
