{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Complete.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import time\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch as pt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from transformers import GPT2ForSequenceClassification, ReformerModelWithLMHead, get_linear_schedule_with_warmup\n",
    "from pytorch_transformers import GPT2Tokenizer\n",
    "from Learning import *\n",
    "device = pt.device(\"cuda\" if pt.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cats, cats_sing, phrases = Listset().load()  # Import word lists dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([317, 1351, 286, 2835, 15921, 25, 22514, 11, 48389, 11, 279, 4127, 11],\n",
       " [317, 1351, 286, 2835, 15921, 25, 22514, 11],\n",
       " [48389, 11, 279, 4127, 11])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"A list of round fruits: apples, oranges, pears,\"), \\\n",
    "    tokenizer.encode(\"A list of round fruits: apples,\"), \\\n",
    "    tokenizer.encode(\"oranges, pears,\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "   ###   Options   ###\n",
    "\n",
    "model_name = \"ernst_one\"             # First, use a mean pooling of the claim and chained evidence\n",
    "test_set_frac = 0.25                 # Fraction of samples to keep as separate test set  (list sets)\n",
    "sample_test_n = 25                   # Number of randomly generated prompts for each sample when testing model\n",
    "log_period_batches = 25              # Batches per iteration\n",
    "learning_rate = 5e-5                 # Adam learning rate (default is 5e-5, sentiment classification example had 2e-5)\n",
    "adam_epsilon = 1e-8                  # Adam epsilon (default is 1e-8)\n",
    "n_sched_warmup = 0                   # Linear scheduler for optimizer number of warmup steps\n",
    "batch_size = bsz = 2                 # Samples per batch\n",
    "N_train_batches = int(1e7 / bsz)     # Total number of batches to show model\n",
    "min_nw, max_nw = 0.17, 0.8           # Minimum and maximum fraction of list to keep when truncating\n",
    "max_listlen = 10                     # Maximum number of words in the list when creating a prompt (at least prior to * max_nw)\n",
    "lidstone_e = 0.0                     # Smoothing for possible words/subwords which are not in the missing list words set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lprompts_encoded = [(tokenizer.encode(prompt), \"types of\" in prompt) for prompt in lprompts]\n",
    "cats_e = [[tokenizer.encode(c + ': ') for c in cs] for cs in cats]\n",
    "cats_sing_e = [[tokenizer.encode(c + ': ') for c in cs] for cs in cats_sing]\n",
    "phrases_e = [[tokenizer.encode(p + ', ') for p in ps] for ps in phrases]\n",
    "N_tokens = len(tokenizer)\n",
    "N_wordlists = len(cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a fixed test set and save to disk, using nw_draw = 15. This function defines the next list token prediction problem\n",
    "def gen_truncated_list(prmt, p):  # prmt = prompt tokens, p = list phrases tokens list\n",
    "    tkzs, sent, tkix = [], [], 0\n",
    "    incl_words = np.random.choice(len(p), min(max_listlen, len(p)), replace=False)\n",
    "    for phz_i in incl_words:\n",
    "        phz_enc = p[phz_i]\n",
    "        tkzs.append((tkix, phz_enc))\n",
    "        tkix += len(phz_enc)\n",
    "        sent += phz_enc\n",
    "    missing_w = [p[i] for i in range(len(p)) if i not in incl_words]\n",
    "    trunc_ix = np.random.randint(round(tkix * min_nw), round(tkix * max_nw))\n",
    "    trunc_n = min([(trunc_ix - ix) for (ix, enc) in tkzs if ix <= trunc_ix])  # N. end phrase tokens\n",
    "    missing_w += [enc for (ix, enc) in tkzs if ix >= (trunc_ix - trunc_n)]\n",
    "    missing_matches = missing_w\n",
    "    if trunc_n > 0:\n",
    "        phr_start = trunc_ix - trunc_n\n",
    "        partial_phr = sent[phr_start:trunc_ix]\n",
    "        missing_matches = [enc for enc in missing_w if enc[:trunc_n] == partial_phr]\n",
    "    next_tokens = [enc[trunc_n] for enc in missing_matches]\n",
    "    norm = len(next_tokens) * (1.0 + lidstone_e)\n",
    "    tunit, y_ = 1 / norm, np.tile(lidstone_e / N_tokens, N_tokens)\n",
    "    for token in next_tokens: y_[token] += tunit\n",
    "    return np.hstack([prmt, sent[:trunc_ix]]), y_\n",
    "def gen_samples_uniform(xcp, xcs, xp, nw, verbose=False):  # Weight testing samples (word lists) uniformly\n",
    "    xs, ys, sqlens, j = [], [], [], 0\n",
    "    for i in range(len(xcp)):\n",
    "        x, y, sqlen = [], [], []\n",
    "        cp, cs, p = xcp[i], xcs[i], xp[i]\n",
    "        for m in range(nw):\n",
    "            prmt, typesof = lprompts_encoded[np.random.randint(len(lprompts_encoded))]\n",
    "            cat_ix = np.random.randint(len(cp))\n",
    "            x_, y_ = gen_truncated_list(np.hstack([prmt, cp[cat_ix] if typesof else cs[cat_ix]]), p)\n",
    "            x.append(x_)\n",
    "            y.append(y_)\n",
    "            sqlen.append(len(x_))\n",
    "            j += 1\n",
    "            if verbose and j % 100 == 0:\n",
    "                sys_print(\"\\rDone: \" + str(j))\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "        sqlens.append(sqlen)\n",
    "    if verbose: sys_print(\"\\rDone: \" + str(j) + \", finished!\\n\")\n",
    "    return xs, ys, sqlens\n",
    "def gen_samples(xcp, xcs, xp, n):  # Maximise training batch diversity by randomly sampling the word lists\n",
    "    xs, ys, sqlens, j = [], [], [], 0\n",
    "    n_sets = len(xcp)\n",
    "    for m in range(n):\n",
    "        i = np.random.randint(n_sets)\n",
    "        cp, cs, p = xcp[i], xcs[i], xp[i]\n",
    "        prmt, typesof = lprompts_encoded[np.random.randint(len(lprompts_encoded))]\n",
    "        cat_ix = np.random.randint(len(cp))\n",
    "        x_, y_ = gen_truncated_list(np.hstack([prmt, cp[cat_ix] if typesof else cs[cat_ix]]), p)\n",
    "        xs.append(x_)\n",
    "        ys.append(y_)\n",
    "        sqlens.append(len(x_))\n",
    "    return xs, ys, sqlens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Done: 50, finished!\n"
     ]
    }
   ],
   "source": [
    "N_test = int(test_set_frac * N_wordlists)\n",
    "N_train = N_wordlists - N_test\n",
    "# test_idx = np.random.choice(N_wordlists, N_test, replace=False)\n",
    "test_idx = np.array([3, 7])\n",
    "cats_e_test, cats_sing_e_test = [cats_e[i] for i in test_idx], [cats_sing_e[i] for i in test_idx]\n",
    "phrases_e_test = [phrases_e[i] for i in test_idx]\n",
    "train_idx = [i for i in range(N_wordlists) if i not in test_idx]\n",
    "cats_e_train, cats_sing_e_train = [cats_e[i] for i in train_idx], [cats_sing_e[i] for i in train_idx]\n",
    "phrases_e_train = [phrases_e[i] for i in train_idx]\n",
    "test_cats = [cats[i][0] for i in test_idx]\n",
    "test_xs, test_ys, test_sqlens = gen_samples_uniform(cats_e_test, cats_sing_e_test, phrases_e_test, sample_test_n, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_ld((test_xs, test_ys, test_sqlens), \"test.data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_xs, test_ys, test_sqlens = load_ld(\"test.data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define next batch function\n",
    "def adapt_form(xs, ys, sqlens):\n",
    "    max_len = max(sqlens)\n",
    "    xs = pt.tensor(np.vstack([np.pad(x, (0, max_len - len(x)), constant_values=50256) for x in xs])).to(device)\n",
    "    ys = pt.tensor(np.vstack(ys)).to(device)\n",
    "    sqlens = pt.tensor(np.asarray(sqlens)).to(device)\n",
    "    return xs, ys, sqlens\n",
    "def next_batch(sz):\n",
    "    global cats_e_train, cats_sing_e_train, phrases_e_train\n",
    "    xs, ys, sqlens = gen_samples(cats_e_train, cats_sing_e_train, phrases_e_train, sz)\n",
    "    return adapt_form(xs, ys, sqlens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2-large and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2 loaded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "959"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(gc.collect())\n",
    "create_folder(\"models\")\n",
    "create_folder(\"models/pretrained\")\n",
    "create_folder(\"models/pretrained/GPT2SeqClas\")\n",
    "model = GPT2ForSequenceClassification.from_pretrained('gpt2-large',\n",
    "    output_hidden_states=True, output_attentions=True, \n",
    "    cache_dir=\"models/pretrained/GPT2SeqClas\")\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "model.config.pad_token_id = model.config.eos_token_id\n",
    "n_embd = model.config.n_embd\n",
    "model = nn.DataParallel(model, device_ids=list(range(pt.cuda.device_count()))).to(device)\n",
    "print(\"GPT2 loaded\")\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "llayer = nn.Linear(n_embd, len(tokenizer), bias=False)\n",
    "llayer = nn.DataParallel(llayer, device_ids=list(range(pt.cuda.device_count()))).to(device)\n",
    "# softmax = nn.Softmax()\n",
    "bcewl_loss = nn.BCEWithLogitsLoss()\n",
    "# bcewl_loss = nn.DataParallel(bcewl_loss, device_ids=list(range(pt.cuda.device_count()))).to(device)\n",
    "# nll_loss = nn.NLLLoss()\n",
    "# kl_loss = nn.KLDivLoss()\n",
    "optimizer = pt.optim.AdamW(model.parameters(), lr=learning_rate, eps=adam_epsilon)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=n_sched_warmup, num_training_steps=N_train_batches)\n",
    "def train_step():\n",
    "    global model, llayer, bcewl_loss, optimizer, scheduler\n",
    "    x_batch, y_batch, sqlens_batch = next_batch(batch_size)\n",
    "    x_batch, y_batch, sqlens_batch = x_batch.to(device), y_batch.to(device), sqlens_batch.to(device)\n",
    "    \n",
    "    model.zero_grad()\n",
    "    outputs = model(x_batch.long())\n",
    "    out_idx = pt.unsqueeze(pt.unsqueeze(sqlens_batch - 1, 1).repeat((1, n_embd)), 1).type(pt.int64)\n",
    "    outs = pt.gather(outputs[2][-1], 1, out_idx).squeeze(1)\n",
    "    logits = llayer(outs)\n",
    "    \n",
    "#     logsofts = pt.log(softmax(logits))\n",
    "    loss = bcewl_loss(logits, y_batch.float())\n",
    "    correct = pt.mean((y_batch[pt.arange(batch_size), pt.argmax(logits, axis=1)] > (lidstone_e / N_tokens)).float())\n",
    "    loss_, correct_ = loss.detach().cpu().numpy(), correct.detach().cpu().numpy()\n",
    "    \n",
    "    loss.sum().backward()\n",
    "    nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    return loss_, correct_\n",
    "\n",
    "def inference(x, sqlens):\n",
    "    global model, llayer\n",
    "    \n",
    "    x, sqlens = x.to(device), sqlens.to(device)\n",
    "    outputs = model(x.long())\n",
    "    out_idx = pt.unsqueeze(pt.unsqueeze(sqlens - 1, 1).repeat((1, n_embd)), 1).type(pt.int64)\n",
    "    outs = pt.gather(outputs[2][-1], 1, out_idx).squeeze(1)\n",
    "    logits = llayer(outs)\n",
    "    return logits\n",
    "def eval_test(x, y, sqlens):\n",
    "    global bcewl_loss\n",
    "    \n",
    "    with pt.no_grad():\n",
    "        logits = inference(x, sqlens)\n",
    "        loss = bcewl_loss(logits, y.float())\n",
    "        correct = pt.mean((y[pt.arange(x.shape[0]), pt.argmax(logits, axis=1)] > (lidstone_e / N_tokens)).float())\n",
    "        loss_, correct_ = loss.detach().cpu().numpy(), correct.detach().cpu().numpy()\n",
    "    return loss_, correct_\n",
    "\n",
    "# top_next = [self.tokenizer.decode(i.item()).strip() for i in probs.topk(k)[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_i = 0\n",
    "best_acc, best_loss = 0, np.inf\n",
    "best_acc_idx = -1\n",
    "create_folder(\"models\")\n",
    "create_folder(\"model_logs\")\n",
    "create_folder(\"models/\" + model_name)\n",
    "graphs_folder = \"graphs\"\n",
    "create_folder(graphs_folder)\n",
    "train_loss, train_accuracy, test_loss, test_accuracy = [], [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_training(verbose=True):\n",
    "    global model, batch_i, best_acc, best_loss, best_acc_idx, train_loss, train_accuracy, test_loss, test_accuracy\n",
    "    \n",
    "    model.train()\n",
    "    iter_loss, iter_accuracy, b_no_inp = [], [], 0\n",
    "    while batch_i < N_train_batches:\n",
    "        batch_i += 1\n",
    "        gc.collect()\n",
    "        b_loss, b_accuracy = train_step()\n",
    "        if verbose:\n",
    "            sys_print('\\rLoss, accuracy: ' + str(np.mean(b_loss)) + ', ' + str(np.mean(b_accuracy)) + \\\n",
    "                      ' @ batch '+ str(batch_i) + ' (' + str(batch_i * batch_size) + ' samples) complete. ')\n",
    "        iter_loss.append(b_loss)\n",
    "        iter_accuracy.append(b_accuracy)\n",
    "        \n",
    "        if (batch_i - 1) % log_period_batches == 0:  # Test on test set\n",
    "            loss, accuracy = [], []\n",
    "            for i in range(N_test):\n",
    "                test_X, test_Y, test_Sqlens = adapt_form(test_xs[i], test_ys[i], test_sqlens[i])\n",
    "                feed_batches = [range(len(test_X))[i * bsz:(i + 1) * bsz] for i in range((len(test_X) // bsz) + 1)]\n",
    "                ls, cs = zip(*[eval_test(test_X[inds], test_Y[inds], test_Sqlens[inds]) for inds in feed_batches])\n",
    "                loss.append(np.mean(ls))\n",
    "                accuracy.append(np.mean(cs))\n",
    "                print('\\n' + test_cats[i] + ': ' + str(loss[-1]) + ', ' + str(accuracy[-1]))\n",
    "            \n",
    "            test_l, test_a = np.mean(loss), np.mean(accuracy)\n",
    "            test_loss.append(test_l)\n",
    "            test_accuracy.append(test_a)\n",
    "            train_l, train_a = np.mean(iter_loss), np.mean(iter_accuracy)\n",
    "            train_loss.append(train_l)\n",
    "            train_accuracy.append(train_a)\n",
    "            iter_loss, iter_accuracy = [], []\n",
    "            \n",
    "            val_a = 0\n",
    "            if test_a > best_acc:      # Save best accuracy model\n",
    "                best_acc = test_a\n",
    "                best_loss = test_l\n",
    "                best_acc_idx = batch_i // log_period_batches\n",
    "                pt.save({\"model\": model.state_dict(),\n",
    "                         \"llayer\": llayer.state_dict(),\n",
    "#                          \"softrmax\": softrmax.state_dict(),\n",
    "                         \"bcewl_loss\": bcewl_loss.state_dict(),\n",
    "#                          \"nll_loss\": nll_loss.state_dict(),\n",
    "#                          \"kl_loss\": kl_loss.state_dict(),\n",
    "                         \"optimizer\": optimizer.state_dict(),\n",
    "                         \"scheduler\": scheduler.state_dict(),\n",
    "                         }, \"./models/\" + model_name + '/' + model_name)\n",
    "                b_no_inp = 0\n",
    "            else:\n",
    "                b_no_inp += log_period_batches\n",
    "                \n",
    "            if verbose:\n",
    "                clear_output()\n",
    "                print(\"Batch\", batch_i, ':', train_a, test_a, \"loss:\", train_l, test_l, \\\n",
    "                      \"Best:\", best_acc, best_loss, 'idx:', best_acc_idx)\n",
    "                fig = plt.figure()\n",
    "                fig.set_size_inches(16, 5)\n",
    "                g = fig.add_subplot(1,2,1)\n",
    "                g.grid()\n",
    "                g.plot(train_accuracy, label='train acc')\n",
    "                g.plot(test_accuracy, label='test acc')\n",
    "                g.legend(loc='lower right')\n",
    "#                 g.axhline(y=0.714, ls='--', color='grey')\n",
    "\n",
    "                g = fig.add_subplot(1,2,2)\n",
    "                g.grid()\n",
    "                g.plot(train_loss, label='train loss')\n",
    "                g.plot(test_loss, label='test loss')\n",
    "                g.legend(loc='upper right')\n",
    "\n",
    "                save_ld((train_accuracy, test_accuracy, train_loss, test_loss),\n",
    "                        \"model_logs/\" + model_name + '_log_latest', pad=False)\n",
    "                plt.savefig(graphs_folder + '/' + model_name + \"_curve_latest\" + '.pdf', format='pdf')\n",
    "                plt.show()\n",
    "    return best_acc, best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 : 0.0 0.0 loss: 0.72812194 0.7089922 Best: 0 inf idx: -1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 26.00 MiB (GPU 0; 15.78 GiB total capacity; 14.07 GiB already allocated; 13.75 MiB free; 14.24 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-5ff61b84ca1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0miterate_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-caa1f024ffe8>\u001b[0m in \u001b[0;36miterate_training\u001b[0;34m(verbose)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mbatch_i\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mb_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             sys_print('\\rLoss, accuracy: ' + str(np.mean(b_loss)) + ', ' + str(np.mean(b_accuracy)) + \\\n",
      "\u001b[0;32m<ipython-input-13-8d3953488552>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mloss_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 26.00 MiB (GPU 0; 15.78 GiB total capacity; 14.07 GiB already allocated; 13.75 MiB free; 14.24 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "print(gc.collect())\n",
    "iterate_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to load a model\n",
    "# gc.collect()\n",
    "# checkpoint = pt.load(\"./models/\" + model_name + '/' + model_name)\n",
    "# model.load_state_dict(checkpoint['model'])\n",
    "# llayer.load_state_dict(checkpoint['llayer'])\n",
    "# bcewl_loss.load_state_dict(checkpoint['bcewl_loss'])\n",
    "# optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "# scheduler.load_state_dict(checkpoint['scheduler'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_top_p_filtering(logits, top_k=0, top_p=0.0, filter_value=-float('Inf')):\n",
    "    \"\"\" Filter a distribution of logits using top-k and/or nucleus (top-p) filtering\n",
    "        Args:\n",
    "            logits: logits distribution shape (vocabulary size)\n",
    "            top_k >0: keep only top k tokens with highest probability (top-k filtering).\n",
    "            top_p >0.0: keep the top tokens with cumulative probability >= top_p (nucleus filtering).\n",
    "                Nucleus filtering is described in Holtzman et al. (http://arxiv.org/abs/1904.09751)\n",
    "    \"\"\"\n",
    "    assert logits.dim() == 1  # batch size 1 for now - could be updated for more but the code would be less clear\n",
    "    top_k = min(top_k, logits.size(-1))  # Safety check\n",
    "    if top_k > 0:\n",
    "        # Remove all tokens with a probability less than the last token of the top-k\n",
    "        indices_to_remove = logits < pt.topk(logits, top_k)[0][..., -1, None]\n",
    "        logits[indices_to_remove] = filter_value\n",
    "\n",
    "    if top_p > 0.0:\n",
    "        sorted_logits, sorted_indices = pt.sort(logits, descending=True)\n",
    "        cumulative_probs = pt.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n",
    "\n",
    "        # Remove tokens with cumulative probability above the threshold\n",
    "        sorted_indices_to_remove = cumulative_probs > top_p\n",
    "        # Shift the indices to the right to keep also the first token above the threshold\n",
    "        sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n",
    "        sorted_indices_to_remove[..., 0] = 0\n",
    "\n",
    "        indices_to_remove = sorted_indices[sorted_indices_to_remove]\n",
    "        logits[indices_to_remove] = filter_value\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_next_token(sent, top_k=-1, top_p=0.9, temperature=1.0):\n",
    "    tokens = tokenizer.encode(sent)\n",
    "    x = pt.tensor([tokens])\n",
    "    logits = inference(x, pt.tensor([len(tokens)]))[0]\n",
    "    logits /= temperature\n",
    "    logits = top_k_top_p_filtering(logits, top_k=top_k, top_p=top_p)\n",
    "    probs = F.softmax(logits, dim=0)\n",
    "    token = pt.multinomial(probs, 1).numpy()[0]\n",
    "    tokens += [token]\n",
    "    sent = tokenizer.decode(tokens)\n",
    "    print(sent)\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentence = \"A list of types of drink: coffee, water, tea, coke, lemonade, milkshake,\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentence = append_next_token(input_sentence, top_k=-1, top_p=0.9, temperature=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
