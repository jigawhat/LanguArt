{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A fine-tuned language model for pictionary word list completion (topic/category phrase + example words -> list of 30 examples). For example, one may complete the list\n",
    "\n",
    "\"A list of round fruits: peach, apricot, lime, plum,\"\n",
    "\n",
    "with\n",
    "\n",
    "\"mango, cherry, pineapple, strawberry, pumpkin, watermelon, orange, pomegranate, melon, apple, pear, grapefruit, papaya, lemon, kiwi, passionfruit, blueberry, raspberry, blackberry, cantaloupe, nectarine, pitaya, persimmon, durian, guava, jackfruit, avocado, lychee, soursop, guarana, mangosteen, blackcurrant, cranberry\"\n",
    "\n",
    "using this model. These words should be compatible with pictionary/skribbl.io; i.e., \"sketchable\" within a few minutes, and easily recognisable. Scroll to the end for more examples, or see the file `data/examples.txt`. Sketchability parameter estimation examples can also be found in `data/data.tsv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import time\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch as pt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from transformers import GPT2ForSequenceClassification, GPT2LMHeadModel, ReformerModelWithLMHead, \\\n",
    "                         get_linear_schedule_with_warmup\n",
    "from pytorch_transformers import GPT2Tokenizer\n",
    "from Learning import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "   ###   Options   ###\n",
    "\n",
    "model_name = \"ernst_one\"\n",
    "gpt2_modelkey = \"gpt2-xl\"         # Pretrained model to start from\n",
    "test_set_frac = 0.25                 # Fraction of samples to keep as separate test set (word lists)\n",
    "sample_test_n = 200                  # Number of randomly generated prompts for each sample when validating model\n",
    "log_period_batches = 10              # Batches per iteration\n",
    "learning_rate = 5e-5                 # Adam learning rate (default is 5e-5, sentiment classification example had 2e-5)\n",
    "adam_epsilon = 1e-8                  # Adam epsilon (default is 1e-8)\n",
    "n_sched_warmup = 0                   # Linear scheduler for optimizer number of warmup steps\n",
    "batch_size = bsz = 64                # Samples per batch\n",
    "N_train_batches = int(1e7 / bsz)     # Total number of batches to show model\n",
    "min_nw, max_nw = 0.7, 0.9            # Minimum and maximum fraction of list to keep when truncating\n",
    "max_listlen = 15                     # Maximum number of words in the list when creating a prompt (at least prior to * max_nw)\n",
    "lidstone_e = 0.01                    # Smoothing for possible words/subwords which are not in the missing list words set\n",
    "max_len = 96                         # Max n. tokens specified in order to match a power of 2, applied prior to *max_nw (tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = \"cuda\" if pt.cuda.is_available() else \"cpu\"\n",
    "d = device = pt.device(dev)\n",
    "# world_size = 1\n",
    "# rank = 0\n",
    "# def setup(rank, world_size): \n",
    "#     os.environ['MASTER_ADDR'] = '127.0.0.1'\n",
    "#     os.environ['MASTER_PORT'] = find_free_port()\n",
    "#     dist.init_process_group(\"gloo\", rank=rank, world_size=world_size)  # initialize the process group\n",
    "# def cleanup():\n",
    "#     dist.destroy_process_group()\n",
    "# # mp.spawn(setup, args=(rank, world_size), nprocs=world_size)\n",
    "# setup(rank, world_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(gpt2_modelkey.replace(\"-xl\", \"-large\"), padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cats, cats_sing, phrases = Listset().load()  # Import word lists dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([317, 1351, 286, 2835, 15921, 25, 22514, 11, 48389, 11, 279, 4127, 11],\n",
       " [317, 1351, 286, 2835, 15921, 25, 22514, 11],\n",
       " [48389, 11, 279, 4127, 11])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"A list of round fruits: apples, oranges, pears,\"), \\\n",
    "    tokenizer.encode(\"A list of round fruits: apples,\"), \\\n",
    "    tokenizer.encode(\"oranges, pears,\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lprompts_encoded = [[tokenizer.encode(prompt), \"types of\" in prompt] for prompt in lprompts]\n",
    "cats_e = [[tokenizer.encode(c + ': ') for c in cs] for cs in cats]\n",
    "cats_sing_e = [[tokenizer.encode(c + ': ') for c in cs] for cs in cats_sing]\n",
    "phrases_e = [[tokenizer.encode(p + ', ') for p in ps] for ps in phrases]\n",
    "N_tokens = len(tokenizer)\n",
    "N_wordlists = len(cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lprompts_encoded = [[pt.tensor(prmt, device=d), pt.tensor(typesof, device=d)] for (prmt, typesof) in lprompts_encoded]\n",
    "cats_e = [[pt.tensor(c, device=d) for c in cs] for cs in cats_e]\n",
    "cats_sing_e = [[pt.tensor(c, device=d) for c in cs] for cs in cats_sing_e]\n",
    "phrases_e = [[pt.tensor(p, device=d) for p in ps] for ps in phrases_e]\n",
    "# N_tokens = pt.tensor(N_tokens, device=d)\n",
    "# max_len = pt.tensor(max_len, device=d)\n",
    "# bsz = pt.tensor(batch_size, device=d)\n",
    "# lprompts_encoded = [[pt.tensor(prmt, device=d), pt.tensor(typesof, device=d)] for (prmt, typesof) in lprompts_encoded]\n",
    "# cats_e = [[pt.tensor(c, device=d) for c in cs] for cs in cats_e]\n",
    "# cats_sing_e = [[pt.tensor(c, device=d) for c in cs] for cs in cats_sing_e]\n",
    "# phrases_e = [[pt.tensor(p, device=d) for p in ps] for ps in phrases_e]\n",
    "# N_tokens = pt.tensor(N_tokens, device=d)\n",
    "# max_len = pt.tensor(max_len, device=d)\n",
    "# bsz = pt.tensor(batch_size, device=d)\n",
    "lidstone_e = pt.tensor(lidstone_e, device=d)\n",
    "y_zero = (lidstone_e / N_tokens).repeat(N_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a fixed test set and save to disk, using nw_draw = 15. This function defines the next list token prediction problem\n",
    "def gen_truncated_list(prmt, p):  # prmt = prompt tokens, p = list word/phrase tokens\n",
    "    tkzs, sent, tkix = [], [], 0\n",
    "    max_ws = max_len - len(prmt)\n",
    "#     incl_words = pt.randperm(len(p))[:min(max_listlen, len(p))]\n",
    "    incl_words = np.random.choice(len(p), min(max_listlen, len(p)), replace=False)\n",
    "    for phz_i in incl_words:\n",
    "        phz_enc = p[phz_i]\n",
    "        tkzs.append((tkix, phz_enc))\n",
    "        tkix += len(phz_enc)\n",
    "        sent.append(phz_enc)\n",
    "        if tkix >= max_ws:\n",
    "            tkix = max_ws\n",
    "            break\n",
    "    sent = pt.hstack(sent)[:max_ws]\n",
    "    missing_w = [p[i] for i in range(len(p)) if i not in incl_words]\n",
    "    trunc_ix = np.random.randint(round(tkix * min_nw), round(tkix * max_nw))\n",
    "    trunc_n = min([(trunc_ix - ix) for (ix, enc) in tkzs if ix <= trunc_ix])  # N. end phrase tokens\n",
    "    missing_w += [enc for (ix, enc) in tkzs if ix >= (trunc_ix - trunc_n)]\n",
    "    missing_matches = missing_w\n",
    "    if trunc_n > 0:\n",
    "        phr_start = trunc_ix - trunc_n\n",
    "        partial_phr = sent[phr_start:trunc_ix]\n",
    "        missing_matches = [enc for enc in missing_w if len(enc) >= trunc_n and all(enc[:trunc_n] == partial_phr)]\n",
    "    next_tokens = [enc[trunc_n] for enc in missing_matches]\n",
    "    norm = len(next_tokens) * (1.0 + lidstone_e)\n",
    "    tunit, y_ = pt.tensor(1 / norm, device=d), y_zero.clone()\n",
    "    for token in next_tokens: y_[token] += tunit\n",
    "    return pt.hstack([prmt, sent[:trunc_ix]]), y_\n",
    "def gen_samples_uniform(xcp, xcs, xp, nw, verbose=False):  # Weight testing samples (word lists) uniformly\n",
    "    xs, ys, sqlens, j = [], [], [], 0\n",
    "    for i in range(len(xcp)):\n",
    "        x, y, sqlen = [], [], []\n",
    "        cp, cs, p = xcp[i], xcs[i], xp[i]\n",
    "        for m in range(nw):\n",
    "            prmt, typesof = lprompts_encoded[np.random.randint(len(lprompts_encoded))]\n",
    "            cat_ix = np.random.randint(len(cp))\n",
    "            x_, y_ = gen_truncated_list(pt.hstack([prmt, cp[cat_ix] if typesof else cs[cat_ix]]), p)\n",
    "            x.append(x_)\n",
    "            y.append(y_)\n",
    "            sqlen.append(len(x_))\n",
    "            j += 1\n",
    "            if verbose and j % 100 == 0:\n",
    "                sys_print(\"\\rDone: \" + str(j))\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "        sqlens.append(sqlen)\n",
    "    if verbose: sys_print(\"\\rDone: \" + str(j) + \", finished!\\n\")\n",
    "    return xs, ys, sqlens\n",
    "def gen_samples(xcp, xcs, xp, n):  # Maximise training batch diversity by randomly sampling the word lists\n",
    "    xs, ys, sqlens, j = [], [], [], 0\n",
    "    n_sets = len(xcp)\n",
    "    for m in range(n):\n",
    "        i = np.random.randint(n_sets)\n",
    "        cp, cs, p = xcp[i], xcs[i], xp[i]\n",
    "        prmt, typesof = lprompts_encoded[np.random.randint(len(lprompts_encoded))]\n",
    "        cat_ix = np.random.randint(len(cp))\n",
    "        x_, y_ = gen_truncated_list(pt.hstack([prmt, cp[cat_ix] if typesof else cs[cat_ix]]), p)\n",
    "        xs.append(x_)\n",
    "        ys.append(y_)\n",
    "        sqlens.append(len(x_))\n",
    "    return xs, ys, sqlens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "['round fruits', 'wild animals', 'chemical elements', 'microorganisms', 'music', 'machine learning algorithms', 'outback experiences', 'buildings']\n",
      "Test:\n",
      "['dramatic and literature elements', 'scientific cycles']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/ipykernel_launcher.py:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: 400, finished!\n"
     ]
    }
   ],
   "source": [
    "N_test = int(test_set_frac * N_wordlists)\n",
    "N_train = N_wordlists - N_test\n",
    "test_idx = np.random.choice(N_wordlists, N_test, replace=False)\n",
    "save_ld(test_idx, \"test.data\")\n",
    "# test_idx = load_ld(\"test.data\")\n",
    "# test_idx = np.array([0, 2])  # Round fruits and chemical elements\n",
    "train_idx = [i for i in range(N_wordlists) if i not in test_idx]\n",
    "print(\"Train:\")\n",
    "print([cats[i][0] for i in train_idx])\n",
    "print(\"Test:\")\n",
    "print([cats[i][0] for i in test_idx])\n",
    "cats_e_test, cats_sing_e_test = [cats_e[i] for i in test_idx], [cats_sing_e[i] for i in test_idx]\n",
    "phrases_e_test = [phrases_e[i] for i in test_idx]\n",
    "cats_e_train, cats_sing_e_train = [cats_e[i] for i in train_idx], [cats_sing_e[i] for i in train_idx]\n",
    "phrases_e_train = [phrases_e[i] for i in train_idx]\n",
    "test_cats = [cats[i][0] for i in test_idx]\n",
    "test_xs, test_ys, test_sqlens = gen_samples_uniform(cats_e_test, cats_sing_e_test, phrases_e_test, sample_test_n, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define next batch function\n",
    "def adapt_form(xs, ys, sqlens):\n",
    "    xs = pt.vstack([F.pad(x, (0, max(0, max_len - len(x))), mode='constant', value=pad_token)[:max_len] for x in xs])\n",
    "    return xs, pt.vstack(ys), pt.tensor(sqlens, device=d)\n",
    "def next_batch(sz):\n",
    "    global cats_e_train, cats_sing_e_train, phrases_e_train\n",
    "    return adapt_form(*gen_samples(cats_e_train, cats_sing_e_train, phrases_e_train, sz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "GPT2 device: cuda:0\n",
      "Pretrained parameters loaded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1271"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if 'model' in locals():\n",
    "    del model\n",
    "pt.cuda.empty_cache()\n",
    "print(gc.collect())\n",
    "create_folder(\"models\")\n",
    "create_folder(\"models/pretrained\")\n",
    "create_folder(\"models/pretrained/GPT2LMHead\")\n",
    "# model_ = GPT2ForSequenceClassification.from_pretrained('gpt2-large',\n",
    "# model_ = GPT2LMHeadModel.from_pretrained('gpt2-xl',\n",
    "# model_ = GPT2LMHeadModel.from_pretrained('gpt2-large',\n",
    "# model_ = GPT2LMHeadModel.from_pretrained('gpt2-medium',\n",
    "model_ = GPT2LMHeadModel.from_pretrained(gpt2_modelkey,\n",
    "    output_hidden_states=False, output_attentions=False, \n",
    "    cache_dir=\"models/pretrained/GPT2LMHead\")\n",
    "# model_.parallelize()\n",
    "device_map = {0: [0, 1, 2],\n",
    "              1: [3, 4, 5, 6, 7, 8],\n",
    "              2: [9, 10, 11, 12, 13, 14],\n",
    "              3: [15, 16, 17, 18, 19, 20],\n",
    "              4: [21, 22, 23, 24, 25, 26, 27],\n",
    "              5: [28, 29, 30, 31, 32, 33, 34],\n",
    "              6: [35, 36, 37, 38, 39, 40, 41],\n",
    "              7: [42, 43, 44, 45, 46, 47],\n",
    "             }\n",
    "model_.parallelize(device_map)\n",
    "# model_ = model_.to(d)\n",
    "print(\"GPT2 device:\", model_.device)\n",
    "model_.resize_token_embeddings(N_tokens)\n",
    "pad_token = model_.config.pad_token_id = model_.config.eos_token_id\n",
    "pad_token = pt.tensor(pad_token, device=d)\n",
    "n_embd = pt.tensor(model_.config.n_embd, device=d)\n",
    "# model = nn.parallel.DistributedDataParallel(model_, device_ids=[d])\n",
    "# model = nn.DataParallel(\n",
    "#     model_, device_ids=list(range(pt.cuda.device_count()))) if dev != \"cpu\" else model_\n",
    "model = model_\n",
    "print(\"Pretrained parameters loaded\")\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "llayer = None #nn.Linear(n_embd, N_tokens, bias=False).to(d)#.cpu()\n",
    "# nn.init.xavier_uniform_(llayer.weight)\n",
    "# llayer = nn.DataParallel(llayer, device_ids=list(range(pt.cuda.device_count()))) if dev != \"cpu\" else llayer\n",
    "# llayer = nn.parallel.DistributedDataParallel(llayer, device_ids=list(range(pt.cuda.device_count()))).to(d)\n",
    "# softmax = nn.Softmax()\n",
    "bcewl_loss = nn.BCEWithLogitsLoss()#.to(d)#.cpu()\n",
    "# bcewl_loss = nn.DataParallel(bcewl_loss, device_ids=list(range(pt.cuda.device_count()))).to(d) if dev != \"cpu\" else bcewl_loss\n",
    "# bcewl_loss = nn.parallel.DistributedDataParallel(bcewl_loss, device_ids=list(range(pt.cuda.device_count()))).to(d)\n",
    "# nll_loss = nn.NLLLoss()\n",
    "# kl_loss = nn.KLDivLoss()\n",
    "optimizer = pt.optim.AdamW(model.parameters(), lr=learning_rate, eps=adam_epsilon)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=n_sched_warmup, num_training_steps=N_train_batches)\n",
    "def sequence_mask(lengths, maxlen=None, dtype=pt.int):\n",
    "    if maxlen is None:\n",
    "        maxlen = lengths.max()\n",
    "    row_vector = pt.arange(0, maxlen, 1, device=d)\n",
    "    matrix = pt.unsqueeze(lengths, dim=-1)\n",
    "    mask = row_vector < matrix\n",
    "\n",
    "    mask = mask.type(dtype)\n",
    "    return mask\n",
    "def train_step():\n",
    "    global model, llayer, bcewl_loss, optimizer, bsz, scheduler\n",
    "    x_batch, y_batch, sqlens_batch = next_batch(bsz)\n",
    "\n",
    "#     for x in x_batch.cpu().detach().numpy():\n",
    "#         print(tokenizer.decode(x))\n",
    "    model.zero_grad()\n",
    "    mask = sequence_mask(sqlens_batch, max_len)\n",
    "    outputs = model(x_batch.long(), attention_mask=mask)  # Get logits\n",
    "    out_idx = pt.unsqueeze(pt.unsqueeze(sqlens_batch - 1, 1).repeat((1, N_tokens)), 1).type(pt.int64)\n",
    "    outs = pt.gather(outputs[0], 1, out_idx).squeeze(1)\n",
    "#     outs = outputs[0][:, -1]\n",
    "#     logits = llayer(outs)\n",
    "    logits = outs\n",
    "    \n",
    "#     logsofts = pt.log(softmax(logits))\n",
    "    loss = bcewl_loss(logits, y_batch.float())\n",
    "    loss = loss.mean()\n",
    "    correct = pt.mean((y_batch[pt.arange(batch_size), pt.argmax(logits, axis=1)] > (lidstone_e / N_tokens)).float())\n",
    "    loss_, correct_ = loss.detach().cpu().numpy(), correct.detach().cpu().numpy()\n",
    "    \n",
    "    loss.backward()\n",
    "    nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    return loss_, correct_\n",
    "\n",
    "def inference(x, sqlens):\n",
    "    global model, llayer\n",
    "\n",
    "    x, sqlens = x, sqlens\n",
    "#     for x_ in x.cpu().detach().numpy():\n",
    "#         print(tokenizer.decode(x_))\n",
    "    mask = sequence_mask(sqlens, max_len)\n",
    "    outputs = model(x.long(), attention_mask=mask)  # Get logits\n",
    "    out_idx = pt.unsqueeze(pt.unsqueeze(sqlens - 1, 1).repeat((1, N_tokens)), 1).type(pt.int64)\n",
    "    outs = pt.gather(outputs[0], 1, out_idx).squeeze(1)\n",
    "#     outs = outputs[0][:, -1]\n",
    "#     logits = llayer(outs)\n",
    "    logits = outs\n",
    "    return logits\n",
    "def eval_test(x, y, sqlens):\n",
    "    global bcewl_loss\n",
    "\n",
    "    with pt.no_grad():\n",
    "        logits = inference(x, sqlens)\n",
    "        loss = bcewl_loss(logits, y.float())#.to(d)#.cpu()\n",
    "        loss = loss.mean()\n",
    "        correct = pt.mean((y[pt.arange(x.shape[0]), pt.argmax(logits, axis=1)] > (lidstone_e / N_tokens)).float())\n",
    "        loss_, correct_ = loss.detach().cpu().numpy(), correct.detach().cpu().numpy()\n",
    "    return loss_, correct_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_i = 0\n",
    "best_acc, best_loss = 0, np.inf\n",
    "best_acc_idx = -1\n",
    "out_str = ''\n",
    "create_folder(\"models\")\n",
    "create_folder(\"model_logs\")\n",
    "create_folder(\"models/\" + model_name)\n",
    "graphs_folder = \"graphs\"\n",
    "create_folder(graphs_folder)\n",
    "train_loss, train_accuracy, test_loss, test_accuracy = [], [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_training(verbose=True):\n",
    "    global model, batch_i, best_acc, best_loss, best_acc_idx, train_loss, train_accuracy, test_loss, test_accuracy\n",
    "    \n",
    "    model.train()\n",
    "    iter_loss, iter_accuracy, b_no_inp = [], [], 0\n",
    "    while batch_i < N_train_batches:\n",
    "        batch_i += 1\n",
    "        if batch_i > 1:\n",
    "            gc.collect()\n",
    "            if dev != \"cpu\": pt.cuda.empty_cache()\n",
    "            b_loss, b_accuracy = train_step()\n",
    "            if verbose:\n",
    "                sys_print('\\rLoss, accuracy: ' + str(np.mean(b_loss)) + ', ' + str(np.mean(b_accuracy)) + \\\n",
    "                          ' @ batch '+ str(batch_i - 1) + ' (' + str((batch_i - 1) * batch_size) + ' samples) complete.                  ')\n",
    "            iter_loss.append(b_loss)\n",
    "            iter_accuracy.append(b_accuracy)\n",
    "\n",
    "        if (batch_i - 1) % log_period_batches == 0:  # Test on test set\n",
    "            model.eval()\n",
    "            loss, accuracy = [], []\n",
    "            out_str = '\\n'\n",
    "            for i in range(N_test):\n",
    "                test_X, test_Y, test_Sqlens = adapt_form(test_xs[i], test_ys[i], test_sqlens[i])\n",
    "                feed_batches = [range(len(test_X))[i * bsz:(i + 1) * bsz] for i in range((len(test_X) // bsz) + \\\n",
    "                                                                                        (1 if (len(test_X) % bsz) != 0 else 0))]\n",
    "                if dev != \"cpu\": pt.cuda.empty_cache()\n",
    "                ls, cs = zip(*[eval_test(test_X[inds], test_Y[inds], test_Sqlens[inds]) for inds in feed_batches])\n",
    "                loss.append(np.mean(ls))\n",
    "                accuracy.append(np.mean(cs))\n",
    "                out_str += test_cats[i] + ': ' + str(loss[-1]) + ', ' + str(accuracy[-1]) + '\\n'\n",
    "            \n",
    "            test_l, test_a = np.mean(loss), np.mean(accuracy)\n",
    "            test_loss.append(test_l)\n",
    "            test_accuracy.append(test_a)\n",
    "            if batch_i == 1:\n",
    "                iter_loss, iter_accuracy = [test_l], [test_a]\n",
    "            train_l, train_a = np.mean(iter_loss), np.mean(iter_accuracy)\n",
    "            train_loss.append(train_l)\n",
    "            train_accuracy.append(train_a)\n",
    "            iter_loss, iter_accuracy = [], []\n",
    "            \n",
    "            val_a = 0\n",
    "            if test_a > best_acc:      # Save best accuracy model\n",
    "                best_acc = test_a\n",
    "                best_loss = test_l\n",
    "                best_acc_idx = (batch_i - 1) // log_period_batches\n",
    "                pt.save({\"model\": model.state_dict(),\n",
    "#                          \"llayer\": llayer.state_dict(),\n",
    "#                          \"softrmax\": softrmax.state_dict(),\n",
    "                         \"bcewl_loss\": bcewl_loss.state_dict(),\n",
    "#                          \"nll_loss\": nll_loss.state_dict(),\n",
    "#                          \"kl_loss\": kl_loss.state_dict(),\n",
    "                         \"optimizer\": optimizer.state_dict(),\n",
    "                         \"scheduler\": scheduler.state_dict(),\n",
    "                         }, \"./models/\" + model_name + '/' + model_name)\n",
    "                b_no_inp = 0\n",
    "            else:\n",
    "                b_no_inp += log_period_batches\n",
    "                \n",
    "            if verbose:\n",
    "                clear_output()\n",
    "                print(out_str + \"Batch\", batch_i, ':', train_a, test_a, \"loss:\", train_l, test_l, \\\n",
    "                      \"Best:\", best_acc, best_loss, 'idx:', best_acc_idx)\n",
    "                fig = plt.figure()\n",
    "                fig.set_size_inches(16, 5)\n",
    "                g = fig.add_subplot(1,2,1)\n",
    "                g.grid()\n",
    "                g.plot(train_accuracy, label='train acc')\n",
    "                g.plot(test_accuracy, label='test acc')\n",
    "                g.legend(loc='lower right')\n",
    "#                 g.axhline(y=0.714, ls='--', color='grey')\n",
    "\n",
    "                g = fig.add_subplot(1,2,2)\n",
    "                g.grid()\n",
    "                g.plot(train_loss, label='train loss')\n",
    "                g.plot(test_loss, label='test loss')\n",
    "                g.legend(loc='upper right')\n",
    "\n",
    "                save_ld((train_accuracy, test_accuracy, train_loss, test_loss),\n",
    "                        \"model_logs/\" + model_name + '_log_latest', pad=False)\n",
    "                plt.savefig(graphs_folder + '/' + model_name + \"_curve_latest\" + '.pdf', format='pdf')\n",
    "                plt.show()\n",
    "            model.train()\n",
    "    return best_acc, best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "dramatic and literature elements: 0.00011456228, 0.76171875\n",
      "scientific cycles: 0.00012498499, 0.61328125\n",
      "Batch 701 : 0.9421875 0.6875 loss: 5.2286086e-05 0.000119773635 Best: 0.7285156 0.00011945774 idx: 65\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/ipykernel_launcher.py:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss, accuracy: 5.8171725e-05, 0.953125 @ batch 707 (45248 samples) complete.                  "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-5ff61b84ca1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0miterate_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-51e9a9ccfdc3>\u001b[0m in \u001b[0;36miterate_training\u001b[0;34m(verbose)\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdev\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mb_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                 sys_print('\\rLoss, accuracy: ' + str(np.mean(b_loss)) + ', ' + str(np.mean(b_accuracy)) + \\\n",
      "\u001b[0;32m<ipython-input-13-1d36f3133d92>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mloss_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(gc.collect())\n",
    "iterate_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model (checkpoint)\n",
    "pt.cuda.empty_cache()\n",
    "gc.collect()\n",
    "cpoint = pt.load(\"./models/\" + model_name + '/' + model_name)\n",
    "# cpoint = pt.load(\"./models/\" + 'ernst_one - 2k ts' + \"/\" + model_name)\n",
    "# cpoint = pt.load(\"./models/\" + 'ernst_one - 3k ts' + \"/\" + model_name)  # ~3000 training samples observed has current optimum\n",
    "# cpoint = pt.load(\"./models/\" + 'ernst_one - 30k ts' + \"/\" + model_name)\n",
    "model.load_state_dict(cpoint['model'])\n",
    "bcewl_loss.load_state_dict(cpoint['bcewl_loss'])\n",
    "optimizer.load_state_dict(cpoint['optimizer'])\n",
    "scheduler.load_state_dict(cpoint['scheduler'])\n",
    "# llayer.load_state_dict(cpoint['llayer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_top_p_filtering(logits, top_k=0, top_p=0.0, filter_value=-float('Inf')):\n",
    "    \"\"\" Filter a distribution of logits using top-k and/or nucleus (top-p) filtering\n",
    "        Args:\n",
    "            logits: logits distribution shape (vocabulary size)\n",
    "            top_k >0: keep only top k tokens with highest probability (top-k filtering).\n",
    "            top_p >0.0: keep the top tokens with cumulative probability >= top_p (nucleus filtering).\n",
    "                Nucleus filtering is described in Holtzman et al. (http://arxiv.org/abs/1904.09751)\n",
    "    \"\"\"\n",
    "    assert logits.dim() == 1  # batch size 1 for now - could be updated for more but the code would be less clear\n",
    "    top_k = min(top_k, logits.size(-1))  # Safety check\n",
    "    if top_k > 0:\n",
    "        # Remove all tokens with a probability less than the last token of the top-k\n",
    "        indices_to_remove = logits < pt.topk(logits, top_k)[0][..., -1, None]\n",
    "        logits[indices_to_remove] = filter_value\n",
    "\n",
    "    if top_p > 0.0:\n",
    "        sorted_logits, sorted_indices = pt.sort(logits, descending=True)\n",
    "        cumulative_probs = pt.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n",
    "\n",
    "        # Remove tokens with cumulative probability above the threshold\n",
    "        sorted_indices_to_remove = cumulative_probs > top_p\n",
    "        # Shift the indices to the right to keep also the first token above the threshold\n",
    "        sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n",
    "        sorted_indices_to_remove[..., 0] = 0\n",
    "\n",
    "        indices_to_remove = sorted_indices[sorted_indices_to_remove]\n",
    "        logits[indices_to_remove] = filter_value\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "padder = int(pad_token.detach().cpu().numpy())\n",
    "def append_next_token(sent, top_k=-1, top_p=0.9, temperature=1.0, olen=None):\n",
    "    print(\"k =\", top_k, \", p =\", top_p, \", temp =\", temperature)\n",
    "    global model\n",
    "    if dev != \"cpu\": pt.cuda.empty_cache()\n",
    "    model.eval()\n",
    "    tokens = tokenizer.encode(sent)\n",
    "    ou = tokens.copy()\n",
    "    while len(tokens) < max_len:\n",
    "        tokens += [padder]\n",
    "    x = pt.tensor([tokens], device=d)\n",
    "    logits = inference(x, pt.tensor([len(ou)], device=d))[0]\n",
    "    logits /= temperature\n",
    "    logits = top_k_top_p_filtering(logits, top_k=top_k, top_p=top_p)\n",
    "    probs = F.softmax(logits, dim=0)\n",
    "    token = pt.multinomial(probs, 1).detach().cpu().numpy()[0]\n",
    "    ou += [token]\n",
    "    prev_len = len(sent) if olen is None else olen\n",
    "    sent_new = tokenizer.decode(ou)\n",
    "    print(sent[:prev_len] + '➡' + sent_new[prev_len:])\n",
    "    return sent_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With about half an hour of fine-tuning using 7 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake\" + \\\n",
    "\"\")\n",
    "input_sentence = input_sentence.split(', ')\n",
    "np.random.shuffle(input_sentence)\n",
    "input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "olen = len(input_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.7, temperature=2.0, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # With about half an hour of fine-tuning using 7 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# # Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake\" + \\\n",
    "# \", liquor, wine, juice, beer, milk, soft drink, whiskey, vodka, spirits, soda, ice water, ice cold beer, cider, yoghurt, soda pop, rum, chocolate milk, hot cocoa, alcohol\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.7, temperature=2.0, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # With about half an hour of fine-tuning using 7 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# # Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake\" + \\\n",
    "# \", liquor, wine, juice, beer, milk, soft drink, whiskey, vodka, spirits, soda, ice water, ice cold beer, cider\" + \\\n",
    "# \", yoghurt, soda pop, rum, chocolate milk, hot cocoa, alcohol\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.7, temperature=2.0, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changelog 16/04/2021 5pm: Using log_period=1 (max_len=96) reliably finds improvement, need more data and larger gpt2 (medium+)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With about half an hour of fine-tuning using 7 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake,\" + \\\n",
    "# \" milk, vodka, beer, ice water, soda, lassi, juice, alcohol, whiskey\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.9, temperature=2.0, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With about half an hour of fine-tuning using 7 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake,\" + \\\n",
    "# \" wine, soda, alcohol, beer, liquor, apple cider, whiskey, milk, bourbon, vodka, cider, lemon juice\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:6])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=30, top_p=0.7, temperature=3.0, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With about half an hour of fine-tuning using 7 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake,\" + \\\n",
    "# \" beer, milk, juice, wine, spirits, alcohol, soda, whiskey, brandy, apple juice, liquor, ice tea, watermelon juice, vodka,\" + \\\n",
    "# \" lemon tea, apple cider, ale, lager, fruit tea, lime cider, cocktail, mocha, red wine, apple soda\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=30, top_p=0.7, temperature=2.0, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changelog 16/04/2021 5am: lr=1e-5, max_len=80, log_period_batches=5 increased accuracy by 8%. Need to add a bunch more data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With about half an hour of fine-tuning using 5 training samples on an NVidia 980 Ti (showing improvements):\n",
    "# Initial input words on first line, those eventually found by repeatedly querying model + recursively adding words on 2nd & 3rd\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake, \" + \\\n",
    "# \"soda, milk, juice, wine, vodka, gin, lime juice, beer, hot chocolate, cider, whiskey, fruit juice, cocktail, liquor, \" + \\\n",
    "# \"spirits, watermelon juice, martini, rum, chocolate milk, orangeade\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.9, temperature=1.89, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without fine tuning (regular GPT-2):\n",
    "# Initial input words on first line, those eventually found by repeatedly querying model on 2nd\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake, \" + \\\n",
    "# \"milk, juice, fruit juice, soda, wine, beer, hot chocolate, chocolate milk, alcohol, cider, ice tea, liquor, spirit\")\n",
    "# input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.75, temperature=1.89, olen=olen) # k = 25 also used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training for too long (in this case ~6:30 hours) overfits\n",
    "# input_sentence = (\"coffee, water, tea, coke, lemonade, milkshake, \" + \\\n",
    "# \"beer, juice, soda, liquor, wine, tequila, spirits, alcohol, cocktail, martini, whiskey, rum, vodka\")\n",
    "# input_sentence = input_sentence.split(', ')\n",
    "# np.random.shuffle(input_sentence)\n",
    "# input_sentence = \"A list of types of drink: \"+', '.join(input_sentence[:10])+', ' # Randomly generate shuffled drinks sublist\n",
    "# olen = len(input_sentence)\n",
    "# input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.9, temperature=1.89, olen=olen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changelog 15/04/2021 11am: Found learning rate 1e-7, max_listlen 15, min_nw 0.7, max_nw 0.9, lidstone_e 0.01 ACTUALLY WORKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No fine tuning (testing gpt2) (old append function):\n",
    "# input_sentence = \"A list of types of drink: coffee, water, tea, coke, lemonade, milkshake\"\n",
    "# input_sentence = append_next_token(input_sentence, top_k=25, top_p=0.75, temperature=1.89)\n",
    "# A list of types of drink: juice, tea, cider, lemonade, milk, beer, hot chocolate,➡ ice cold milk. Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working (reproducible) examples using various non-fine-tuned models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT3 (via AI Dungeon) (Randomness = 2.0, model = Dragon):\n",
    "# sentence = \"A list of ML algorithms: inverse reinforcement learning, ELMo, decision tree, LDA, \"\n",
    "# expected_completion = \"MLP, MLL, MMM. You can't believe you're actually using these things!\"\n",
    "\n",
    "# sentence = \"A list of animals seen in the wild: wolffish, woodlouse, sheep, zebra, yak, \"\n",
    "# expected_completion = \"goat, fox, dog, rat. You're guessing that a lot of other animals have been seen as well; maybe even all the animals on your list except for wolf and rat?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT2 (via Write with Transformer) (Top-p = 0.67, temperature = 1.89, max time = 1.9):\n",
    "# sentence = \"A list of round fruits: peach, apricot, lime, plum, blackberry, cantaloupe, nectarine, pitaya, persimmon, \"\n",
    "# expected_completion = \"mango, papaya and raspberry, as also many\"\n",
    "\n",
    "# sentence = \"A list of chemical elements: hydrogen, carbon, oxygen, nitrogen, gold, \"\n",
    "# expected_completion = \"silver, aluminum, potassium and phosphorus; atomic number.\"\n",
    "\n",
    "# sentence = \"A list of microbes found on earth: bacteria, virus, prokaryote, amoeba, \"\n",
    "# expected_completion = \"archaea, algae, nematode, euk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
