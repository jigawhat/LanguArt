{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A fine-tuned language model for pictionary word list completion (topic/category phrase + example words -> list of 30 examples). For example, one may complete the list\n",
    "\n",
    "\"A list of round fruits: peach, apricot, lime, plum,\"\n",
    "\n",
    "with\n",
    "\n",
    "\"mango, cherry, pineapple, strawberry, pumpkin, watermelon, orange, pomegranate, melon, apple, pear, grapefruit, papaya, lemon, kiwi, passionfruit, blueberry, raspberry, blackberry, cantaloupe, nectarine, pitaya, persimmon, durian, guava, jackfruit, avocado, lychee, soursop, guarana, mangosteen, blackcurrant, cranberry\"\n",
    "\n",
    "using this model. These words should be compatible with pictionary/skribbl.io; i.e., \"sketchable\" within a few minutes, and easily recognisable. Scroll to the end for more examples, or see the file `data/examples.txt`. Sketchability parameter estimation examples can also be found in `data/data.tsv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0123 15:16:02.665653 13448 modeling_bert.py:226] Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n",
      "I0123 15:16:02.673632 13448 modeling_xlnet.py:339] Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\alfew\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Complete.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import time\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch as pt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from transformers import GPT2ForSequenceClassification, GPT2LMHeadModel, ReformerModelWithLMHead, \\\n",
    "                         get_linear_schedule_with_warmup\n",
    "from pytorch_transformers import GPT2Tokenizer\n",
    "from Learning import *\n",
    "dev = \"cpu\"#\"cuda\" if pt.cuda.is_available() else \"cpu\"\n",
    "d = device = pt.device(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0123 15:16:32.986577 13448 tokenization_utils.py:384] loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-large-vocab.json from cache at C:\\Users\\alfew\\.cache\\torch\\pytorch_transformers\\69f8d734111f39eaa51a85907bfdc81a7ef42242d638ffab6f77df305402b2b2.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "I0123 15:16:32.987574 13448 tokenization_utils.py:384] loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-large-merges.txt from cache at C:\\Users\\alfew\\.cache\\torch\\pytorch_transformers\\38d28acc17953e356348dca948e152c653c0ccf5058a552eea30168e27f02046.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n"
     ]
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2-large\", padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cats, cats_sing, phrases = Listset().load()  # Import word lists dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([317, 1351, 286, 2835, 15921, 25, 22514, 11, 48389, 11, 279, 4127, 11],\n",
       " [317, 1351, 286, 2835, 15921, 25, 22514, 11],\n",
       " [48389, 11, 279, 4127, 11])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"A list of round fruits: apples, oranges, pears,\"), \\\n",
    "    tokenizer.encode(\"A list of round fruits: apples,\"), \\\n",
    "    tokenizer.encode(\"oranges, pears,\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "   ###   Options   ###\n",
    "\n",
    "model_name = \"ernst_one\"\n",
    "test_set_frac = 0.25                 # Fraction of samples to keep as separate test set (word lists)\n",
    "sample_test_n = 25                   # Number of randomly generated prompts for each sample when testing model\n",
    "log_period_batches = 25              # Batches per iteration\n",
    "learning_rate = 1e-5                 # Adam learning rate (default is 5e-5, sentiment classification example had 2e-5)\n",
    "adam_epsilon = 1e-8                  # Adam epsilon (default is 1e-8)\n",
    "n_sched_warmup = 0                   # Linear scheduler for optimizer number of warmup steps\n",
    "batch_size = bsz = 8                 # Samples per batch\n",
    "N_train_batches = int(1e7 / bsz)     # Total number of batches to show model\n",
    "min_nw, max_nw = 0.17, 0.8           # Minimum and maximum fraction of list to keep when truncating\n",
    "max_listlen = 20                     # Maximum number of words in the list when creating a prompt (at least prior to * max_nw)\n",
    "lidstone_e = 0.0                     # Smoothing for possible words/subwords which are not in the missing list words set\n",
    "max_len = 96                         # Manually specified in order to match a power of 2 (todo: find opt 64 < x < 96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lprompts_encoded = [[tokenizer.encode(prompt), \"types of\" in prompt] for prompt in lprompts]\n",
    "cats_e = [[tokenizer.encode(c + ': ') for c in cs] for cs in cats]\n",
    "cats_sing_e = [[tokenizer.encode(c + ': ') for c in cs] for cs in cats_sing]\n",
    "phrases_e = [[tokenizer.encode(p + ', ') for p in ps] for ps in phrases]\n",
    "N_tokens = len(tokenizer)\n",
    "N_wordlists = len(cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lprompts_encoded = [[pt.tensor(prmt, device=d), pt.tensor(typesof, device=d)] for (prmt, typesof) in lprompts_encoded]\n",
    "cats_e = [[pt.tensor(c, device=d) for c in cs] for cs in cats_e]\n",
    "cats_sing_e = [[pt.tensor(c, device=d) for c in cs] for cs in cats_sing_e]\n",
    "phrases_e = [[pt.tensor(p, device=d) for p in ps] for ps in phrases_e]\n",
    "N_tokens = pt.tensor(N_tokens, device=d)\n",
    "max_len = pt.tensor(max_len, device=d)\n",
    "bsz = pt.tensor(batch_size, device=d)\n",
    "y_zero = (lidstone_e / N_tokens).repeat(N_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a fixed test set and save to disk, using nw_draw = 15. This function defines the next list token prediction problem\n",
    "def gen_truncated_list(prmt, p):  # prmt = prompt tokens, p = list phrases tokens list\n",
    "    tkzs, sent, tkix = [], [], 0\n",
    "#     incl_words = pt.randperm(len(p))[:min(max_listlen, len(p))]\n",
    "    incl_words = np.random.choice(len(p), min(max_listlen, len(p)), replace=False)\n",
    "    for phz_i in incl_words:\n",
    "        phz_enc = p[phz_i]\n",
    "        tkzs.append((tkix, phz_enc))\n",
    "        tkix += len(phz_enc)\n",
    "        sent.append(phz_enc)\n",
    "    sent = pt.hstack(sent)\n",
    "    missing_w = [p[i] for i in range(len(p)) if i not in incl_words]\n",
    "    trunc_ix = np.random.randint(round(tkix * min_nw), round(tkix * max_nw))\n",
    "    trunc_n = min([(trunc_ix - ix) for (ix, enc) in tkzs if ix <= trunc_ix])  # N. end phrase tokens\n",
    "    missing_w += [enc for (ix, enc) in tkzs if ix >= (trunc_ix - trunc_n)]\n",
    "    missing_matches = missing_w\n",
    "    if trunc_n > 0:\n",
    "        phr_start = trunc_ix - trunc_n\n",
    "        partial_phr = sent[phr_start:trunc_ix]\n",
    "        missing_matches = [enc for enc in missing_w if len(enc) >= trunc_n and all(enc[:trunc_n] == partial_phr)]\n",
    "    next_tokens = [enc[trunc_n] for enc in missing_matches]\n",
    "    norm = len(next_tokens) * (1.0 + lidstone_e)\n",
    "    tunit, y_ = pt.tensor(1 / norm, device=d), y_zero.clone()\n",
    "    for token in next_tokens: y_[token] += tunit\n",
    "    return pt.hstack([prmt, sent[:trunc_ix]]), y_\n",
    "def gen_samples_uniform(xcp, xcs, xp, nw, verbose=False):  # Weight testing samples (word lists) uniformly\n",
    "    xs, ys, sqlens, j = [], [], [], 0\n",
    "    for i in range(len(xcp)):\n",
    "        x, y, sqlen = [], [], []\n",
    "        cp, cs, p = xcp[i], xcs[i], xp[i]\n",
    "        for m in range(nw):\n",
    "            prmt, typesof = lprompts_encoded[np.random.randint(len(lprompts_encoded))]\n",
    "            cat_ix = np.random.randint(len(cp))\n",
    "            x_, y_ = gen_truncated_list(pt.hstack([prmt, cp[cat_ix] if typesof else cs[cat_ix]]), p)\n",
    "            x.append(x_)\n",
    "            y.append(y_)\n",
    "            sqlen.append(len(x_))\n",
    "            j += 1\n",
    "            if verbose and j % 100 == 0:\n",
    "                sys_print(\"\\rDone: \" + str(j))\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "        sqlens.append(sqlen)\n",
    "    if verbose: sys_print(\"\\rDone: \" + str(j) + \", finished!\\n\")\n",
    "    return xs, ys, sqlens\n",
    "def gen_samples(xcp, xcs, xp, n):  # Maximise training batch diversity by randomly sampling the word lists\n",
    "    xs, ys, sqlens, j = [], [], [], 0\n",
    "    n_sets = len(xcp)\n",
    "    for m in range(n):\n",
    "        i = np.random.randint(n_sets)\n",
    "        cp, cs, p = xcp[i], xcs[i], xp[i]\n",
    "        prmt, typesof = lprompts_encoded[np.random.randint(len(lprompts_encoded))]\n",
    "        cat_ix = np.random.randint(len(cp))\n",
    "        x_, y_ = gen_truncated_list(pt.hstack([prmt, cp[cat_ix] if typesof else cs[cat_ix]]), p)\n",
    "        xs.append(x_)\n",
    "        ys.append(y_)\n",
    "        sqlens.append(len(x_))\n",
    "    return xs, ys, sqlens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Done: 50, finished!\n"
     ]
    }
   ],
   "source": [
    "N_test = int(test_set_frac * N_wordlists)\n",
    "N_train = N_wordlists - N_test\n",
    "# test_idx = np.random.choice(N_wordlists, N_test, replace=False)\n",
    "test_idx = np.array([3, 7])\n",
    "cats_e_test, cats_sing_e_test = [cats_e[i] for i in test_idx], [cats_sing_e[i] for i in test_idx]\n",
    "phrases_e_test = [phrases_e[i] for i in test_idx]\n",
    "train_idx = [i for i in range(N_wordlists) if i not in test_idx]\n",
    "cats_e_train, cats_sing_e_train = [cats_e[i] for i in train_idx], [cats_sing_e[i] for i in train_idx]\n",
    "phrases_e_train = [phrases_e[i] for i in train_idx]\n",
    "test_cats = [cats[i][0] for i in test_idx]\n",
    "test_xs, test_ys, test_sqlens = gen_samples_uniform(cats_e_test, cats_sing_e_test, phrases_e_test, sample_test_n, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_ld((test_xs, test_ys, test_sqlens), \"test.data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_xs, test_ys, test_sqlens = load_ld(\"test.data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define next batch function\n",
    "def adapt_form(xs, ys, sqlens):\n",
    "    xs = pt.vstack([F.pad(x, (0, max_len - len(x)), mode='constant', value=pad_token) for x in xs])\n",
    "    return xs, pt.vstack(ys), pt.tensor(sqlens, device=d)\n",
    "def next_batch(sz):\n",
    "    global cats_e_train, cats_sing_e_train, phrases_e_train\n",
    "    return adapt_form(*gen_samples(cats_e_train, cats_sing_e_train, phrases_e_train, sz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrained parameters loaded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "979"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(gc.collect())\n",
    "create_folder(\"models\")\n",
    "create_folder(\"models/pretrained\")\n",
    "create_folder(\"models/pretrained/GPT2LMHead\")\n",
    "# model_ = GPT2ForSequenceClassification.from_pretrained('gpt2-large',\n",
    "model_ = GPT2LMHeadModel.from_pretrained('gpt2-large',\n",
    "    output_hidden_states=True, output_attentions=True, \n",
    "    cache_dir=\"models/pretrained/GPT2LMHead\")\n",
    "# model_.parallelize()\n",
    "model_ = model_.to(d)\n",
    "print(\"GPT2 device:\", model_.device)\n",
    "model_.resize_token_embeddings(N_tokens)\n",
    "pad_token = model_.config.pad_token_id = model_.config.eos_token_id\n",
    "pad_token = pt.tensor(pad_token, device=d)\n",
    "n_embd = pt.tensor(model_.config.n_embd, device=d)\n",
    "# model = nn.parallel.DistributedDataParallel(\n",
    "model = nn.DataParallel(\n",
    "    model_, device_ids=list(range(pt.cuda.device_count()))) if dev != \"cpu\" else model_\n",
    "print(\"Pretrained parameters loaded\")\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "llayer = nn.Linear(n_embd, N_tokens, bias=False).to(d)#.cpu()\n",
    "nn.init.xavier_uniform_(llayer.weight)\n",
    "llayer = nn.DataParallel(llayer, device_ids=list(range(pt.cuda.device_count()))) if dev != \"cpu\" else llayer\n",
    "# llayer = nn.parallel.DistributedDataParallel(llayer, device_ids=list(range(pt.cuda.device_count()))).to(d)\n",
    "# softmax = nn.Softmax()\n",
    "bcewl_loss = nn.BCEWithLogitsLoss().to(d)#.cpu()\n",
    "bcewl_loss = nn.DataParallel(bcewl_loss, device_ids=list(range(pt.cuda.device_count()))).to(d) if dev != \"cpu\" else bcewl_loss\n",
    "# bcewl_loss = nn.parallel.DistributedDataParallel(bcewl_loss, device_ids=list(range(pt.cuda.device_count()))).to(d)\n",
    "# nll_loss = nn.NLLLoss()\n",
    "# kl_loss = nn.KLDivLoss()\n",
    "optimizer = pt.optim.AdamW(model.parameters(), lr=learning_rate, eps=adam_epsilon)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=n_sched_warmup, num_training_steps=N_train_batches)\n",
    "def sequence_mask(lengths, maxlen=None, dtype=pt.int):\n",
    "    if maxlen is None:\n",
    "        maxlen = lengths.max()\n",
    "    row_vector = pt.arange(0, maxlen, 1, device=d)\n",
    "    matrix = pt.unsqueeze(lengths, dim=-1)\n",
    "    mask = row_vector < matrix\n",
    "\n",
    "    mask = mask.type(dtype)\n",
    "    return mask\n",
    "def train_step():\n",
    "    global model, llayer, bcewl_loss, optimizer, scheduler, bsz\n",
    "    x_batch, y_batch, sqlens_batch = next_batch(bsz)\n",
    "    \n",
    "    model.zero_grad()\n",
    "    mask = sequence_mask(sqlens_batch, max_len)\n",
    "    outputs = model(x_batch.long(), attention_mask=mask)\n",
    "    out_idx = pt.unsqueeze(pt.unsqueeze(sqlens_batch - 1, 1).repeat((1, n_embd)), 1).type(pt.int64)\n",
    "    outs = pt.gather(outputs[2][-1].to(d), 1, out_idx).squeeze(1)\n",
    "#     outs = pt.gather(outputs[2][-1].cpu(), 1, out_idx).squeeze(1)\n",
    "    logits = llayer(outs)\n",
    "    \n",
    "#     logsofts = pt.log(softmax(logits))\n",
    "    loss = bcewl_loss(logits, y_batch.float())#.to(d)#.cpu()\n",
    "    loss = loss.mean()\n",
    "    correct = pt.mean((y_batch[pt.arange(batch_size), pt.argmax(logits, axis=1)] > (lidstone_e / N_tokens)).float())\n",
    "    loss_, correct_ = loss.detach().cpu().numpy(), correct.detach().cpu().numpy()\n",
    "    \n",
    "    loss.backward()\n",
    "    nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    return loss_, correct_\n",
    "\n",
    "def inference(x, sqlens):\n",
    "    global model, llayer\n",
    "\n",
    "    x, sqlens = x.to(d), sqlens.to(d)#.cpu()\n",
    "    mask = sequence_mask(sqlens, max_len)\n",
    "    outputs = model(x.long(), attention_mask=mask)\n",
    "    out_idx = pt.unsqueeze(pt.unsqueeze(sqlens - 1, 1).repeat((1, n_embd)), 1).type(pt.int64)\n",
    "    outs = pt.gather(outputs[2][-1], 1, out_idx).squeeze(1)\n",
    "#     outs = pt.gather(outputs[2][-1].cpu(), 1, out_idx).squeeze(1)\n",
    "    logits = llayer(outs)\n",
    "    return logits\n",
    "def eval_test(x, y, sqlens):\n",
    "    global bcewl_loss\n",
    "\n",
    "    with pt.no_grad():\n",
    "        logits = inference(x, sqlens)\n",
    "        loss = bcewl_loss(logits, y.float())#.to(d)#.cpu()\n",
    "        loss = loss.mean()\n",
    "        correct = pt.mean((y[pt.arange(x.shape[0]), pt.argmax(logits, axis=1)] > (lidstone_e / N_tokens)).float())\n",
    "        loss_, correct_ = loss.detach().cpu().numpy(), correct.detach().cpu().numpy()\n",
    "    return loss_, correct_\n",
    "\n",
    "# top_next = [self.tokenizer.decode(i.item()).strip() for i in probs.topk(k)[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_i = 0\n",
    "best_acc, best_loss = 0, np.inf\n",
    "best_acc_idx = -1\n",
    "create_folder(\"models\")\n",
    "create_folder(\"model_logs\")\n",
    "create_folder(\"models/\" + model_name)\n",
    "graphs_folder = \"graphs\"\n",
    "create_folder(graphs_folder)\n",
    "train_loss, train_accuracy, test_loss, test_accuracy = [], [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_training(verbose=True):\n",
    "    global model, batch_i, best_acc, best_loss, best_acc_idx, train_loss, train_accuracy, test_loss, test_accuracy\n",
    "    \n",
    "    model.train()\n",
    "    iter_loss, iter_accuracy, b_no_inp = [], [], 0\n",
    "    while batch_i < N_train_batches:\n",
    "        batch_i += 1\n",
    "        gc.collect()\n",
    "        if dev != \"cpu\": pt.cuda.empty_cache()\n",
    "        b_loss, b_accuracy = train_step()\n",
    "        if verbose:\n",
    "            sys_print('\\rLoss, accuracy: ' + str(np.mean(b_loss)) + ', ' + str(np.mean(b_accuracy)) + \\\n",
    "                      ' @ batch '+ str(batch_i) + ' (' + str(batch_i * batch_size) + ' samples) complete.                  ')\n",
    "        iter_loss.append(b_loss)\n",
    "        iter_accuracy.append(b_accuracy)\n",
    "        \n",
    "        if (batch_i - 1) % log_period_batches == 0:  # Test on test set\n",
    "            model.eval()\n",
    "            loss, accuracy = [], []\n",
    "            for i in range(N_test):\n",
    "                test_X, test_Y, test_Sqlens = adapt_form(test_xs[i], test_ys[i], test_sqlens[i])\n",
    "                feed_batches = [range(len(test_X))[i * bsz:(i + 1) * bsz] for i in range((len(test_X) // bsz) + 1)]\n",
    "                if dev != \"cpu\": pt.cuda.empty_cache()\n",
    "                ls, cs = zip(*[eval_test(test_X[inds], test_Y[inds], test_Sqlens[inds]) for inds in feed_batches])\n",
    "                loss.append(np.mean(ls))\n",
    "                accuracy.append(np.mean(cs))\n",
    "                print('\\n' + test_cats[i] + ': ' + str(loss[-1]) + ', ' + str(accuracy[-1]))\n",
    "            \n",
    "            test_l, test_a = np.mean(loss), np.mean(accuracy)\n",
    "            test_loss.append(test_l)\n",
    "            test_accuracy.append(test_a)\n",
    "            train_l, train_a = np.mean(iter_loss), np.mean(iter_accuracy)\n",
    "            train_loss.append(train_l)\n",
    "            train_accuracy.append(train_a)\n",
    "            iter_loss, iter_accuracy = [], []\n",
    "            \n",
    "            val_a = 0\n",
    "            if test_a > best_acc:      # Save best accuracy model\n",
    "                best_acc = test_a\n",
    "                best_loss = test_l\n",
    "                best_acc_idx = batch_i // log_period_batches\n",
    "                pt.save({\"model\": model.state_dict(),\n",
    "                         \"llayer\": llayer.state_dict(),\n",
    "#                          \"softrmax\": softrmax.state_dict(),\n",
    "                         \"bcewl_loss\": bcewl_loss.state_dict(),\n",
    "#                          \"nll_loss\": nll_loss.state_dict(),\n",
    "#                          \"kl_loss\": kl_loss.state_dict(),\n",
    "                         \"optimizer\": optimizer.state_dict(),\n",
    "                         \"scheduler\": scheduler.state_dict(),\n",
    "                         }, \"./models/\" + model_name + '/' + model_name)\n",
    "                b_no_inp = 0\n",
    "            else:\n",
    "                b_no_inp += log_period_batches\n",
    "                \n",
    "            if verbose:\n",
    "                clear_output()\n",
    "                print(\"Batch\", batch_i, ':', train_a, test_a, \"loss:\", train_l, test_l, \\\n",
    "                      \"Best:\", best_acc, best_loss, 'idx:', best_acc_idx)\n",
    "                fig = plt.figure()\n",
    "                fig.set_size_inches(16, 5)\n",
    "                g = fig.add_subplot(1,2,1)\n",
    "                g.grid()\n",
    "                g.plot(train_accuracy, label='train acc')\n",
    "                g.plot(test_accuracy, label='test acc')\n",
    "                g.legend(loc='lower right')\n",
    "#                 g.axhline(y=0.714, ls='--', color='grey')\n",
    "\n",
    "                g = fig.add_subplot(1,2,2)\n",
    "                g.grid()\n",
    "                g.plot(train_loss, label='train loss')\n",
    "                g.plot(test_loss, label='test loss')\n",
    "                g.legend(loc='upper right')\n",
    "\n",
    "                save_ld((train_accuracy, test_accuracy, train_loss, test_loss),\n",
    "                        \"model_logs/\" + model_name + '_log_latest', pad=False)\n",
    "                plt.savefig(graphs_folder + '/' + model_name + \"_curve_latest\" + '.pdf', format='pdf')\n",
    "                plt.show()\n",
    "            model.train()\n",
    "    return best_acc, best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 : 0.0 0.0 loss: 0.6986929 0.69654155 Best: 0 inf idx: -1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Loss, accuracy: 0.69701207, 0.0 @ batch 2 (16 samples) complete.                  "
     ]
    }
   ],
   "source": [
    "print(gc.collect())\n",
    "iterate_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to load a model\n",
    "# gc.collect()\n",
    "# checkpoint = pt.load(\"./models/\" + model_name + '/' + model_name)\n",
    "# model.load_state_dict(checkpoint['model'])\n",
    "# llayer.load_state_dict(checkpoint['llayer'])\n",
    "# bcewl_loss.load_state_dict(checkpoint['bcewl_loss'])\n",
    "# optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "# scheduler.load_state_dict(checkpoint['scheduler'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_top_p_filtering(logits, top_k=0, top_p=0.0, filter_value=-float('Inf')):\n",
    "    \"\"\" Filter a distribution of logits using top-k and/or nucleus (top-p) filtering\n",
    "        Args:\n",
    "            logits: logits distribution shape (vocabulary size)\n",
    "            top_k >0: keep only top k tokens with highest probability (top-k filtering).\n",
    "            top_p >0.0: keep the top tokens with cumulative probability >= top_p (nucleus filtering).\n",
    "                Nucleus filtering is described in Holtzman et al. (http://arxiv.org/abs/1904.09751)\n",
    "    \"\"\"\n",
    "    assert logits.dim() == 1  # batch size 1 for now - could be updated for more but the code would be less clear\n",
    "    top_k = min(top_k, logits.size(-1))  # Safety check\n",
    "    if top_k > 0:\n",
    "        # Remove all tokens with a probability less than the last token of the top-k\n",
    "        indices_to_remove = logits < pt.topk(logits, top_k)[0][..., -1, None]\n",
    "        logits[indices_to_remove] = filter_value\n",
    "\n",
    "    if top_p > 0.0:\n",
    "        sorted_logits, sorted_indices = pt.sort(logits, descending=True)\n",
    "        cumulative_probs = pt.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n",
    "\n",
    "        # Remove tokens with cumulative probability above the threshold\n",
    "        sorted_indices_to_remove = cumulative_probs > top_p\n",
    "        # Shift the indices to the right to keep also the first token above the threshold\n",
    "        sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n",
    "        sorted_indices_to_remove[..., 0] = 0\n",
    "\n",
    "        indices_to_remove = sorted_indices[sorted_indices_to_remove]\n",
    "        logits[indices_to_remove] = filter_value\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_next_token(sent, top_k=-1, top_p=0.9, temperature=1.0):\n",
    "    global model\n",
    "    model.eval()\n",
    "    tokens = tokenizer.encode(sent)\n",
    "    x = pt.tensor([tokens], device=d)\n",
    "    if dev != \"cpu\": pt.cuda.empty_cache()\n",
    "    logits = inference(x, pt.tensor([len(tokens)]), device=d)[0]\n",
    "    logits /= temperature\n",
    "    logits = top_k_top_p_filtering(logits, top_k=top_k, top_p=top_p)\n",
    "    probs = F.softmax(logits, dim=0)\n",
    "    token = pt.multinomial(probs, 1).numpy()[0]\n",
    "    tokens += [token]\n",
    "    sent = tokenizer.decode(tokens)\n",
    "    print(sent)\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentence = \"A list of types of drink: coffee, water, tea, coke, lemonade, milkshake,\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentence = append_next_token(input_sentence, top_k=-1, top_p=0.9, temperature=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working (reproducible) examples using various non-fine-tuned models (proof of concept):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT3 (via AI Dungeon) (Randomness = 2.0, model = Dragon):\n",
    "sentence = \"A list of ML algorithms: inverse reinforcement learning, ELMo, decision tree, LDA, \"\n",
    "expected_completion = \"MLP, MLL, MMM. You can't believe you're actually using these things!\"\n",
    "\n",
    "sentence = \"A list of animals seen in the wild: wolffish, woodlouse, sheep, zebra, yak, \"\n",
    "expected_completion = \"goat, fox, dog, rat. You're guessing that a lot of other animals have been seen as well; maybe even all the animals on your list except for wolf and rat?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT2 (via Write with Transformer) (Top-p = 0.67, temperature = 1.89, max time = 1.9):\n",
    "sentence = \"A list of round fruits: peach, apricot, lime, plum, blackberry, cantaloupe, nectarine, pitaya, persimmon, \"\n",
    "expected_completion = \"mango, papaya and raspberry, as also many\"\n",
    "\n",
    "sentence = \"A list of chemical elements: hydrogen, carbon, oxygen, nitrogen, gold, \"\n",
    "expected_completion = \"silver, aluminum, potassium and phosphorus; atomic number.\"\n",
    "\n",
    "sentence = \"A list of microbes found on earth: bacteria, virus, prokaryote, amoeba, \"\n",
    "expected_completion = \"archaea, algae, nematode, euk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
