{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import inspect\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import *\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import *\n",
    "\n",
    "from Constants import *\n",
    "from Utils import *\n",
    "from Dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(sklearn.tree.tree.DecisionTreeClassifier,\n",
       " sklearn.tree.tree.BaseDecisionTree,\n",
       " abc.NewBase,\n",
       " sklearn.base.BaseEstimator,\n",
       " sklearn.base.ClassifierMixin,\n",
       " object)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inspect.getmro(DecisionTreeClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(combined_csv)\n",
    "df = dataset.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data(dataframe, x_lab, y_lab):\n",
    "    return np.array(dataframe[x_lab]), np.array(dataframe[y_lab])\n",
    "\n",
    "def learn(model, X, Y, scorers):\n",
    "    Y_pr = cross_val_predict(model, X, Y, cv=10)\n",
    "    errs = [scorer(Y, Y_pr, multioutput='raw_values') for scorer in scorers]\n",
    "#     errs = [scorer(Y, Y_pr, multioutput='uniform_average') for scorer in scorers]\n",
    "    return Y_pr, errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Y values to learn\n",
    "Y_labels = Y_labels_default[1:] # All except 'inc', which is binary\n",
    "# Y_labels = Y_labels_default\n",
    "# Y_labels = ['dif', 'nrd', 'skt'] # Sketchability, general, scalar metrics\n",
    "# Y_labels = ['dif', 'nrd', 'skt', 'vis'] # Visual, general, scalar metrics\n",
    "# Y_labels = ['vis', 'phy', 'obj'] # Physical, general, scalar metrics\n",
    "\n",
    "# Define X values to learn from\n",
    "X_labels = X_labels_default\n",
    "\n",
    "# Define models to evaluate\n",
    "models = [\n",
    "    MultiOutputRegressor(GradientBoostingRegressor()),\n",
    "]\n",
    "\n",
    "# Define scoring functions\n",
    "scoring_funcs = [\n",
    "    mean_squared_error,\n",
    "    mean_absolute_error,\n",
    "    explained_variance_score,\n",
    "    mean_squared_log_error,\n",
    "    r2_score\n",
    "]\n",
    "\n",
    "# Train Multi-task models on interval_size-sample increments of data, up to the whole dataset\n",
    "interval_size = 10\n",
    "ns_samples = np.arange(0, df.shape[0], interval_size)[1:]\n",
    "\n",
    "# Take ns_eval_samples samples of random x for each increment, to get accurate results at low n\n",
    "ns_eval_samples = [10] * len(ns_samples)\n",
    "\n",
    "# Load data\n",
    "X, Y = get_data(df, X_labels, Y_labels)\n",
    "\n",
    "results = []\n",
    "for i in range(len(models)):\n",
    "    results += [[]]\n",
    "    for j in range(len(ns_samples)):\n",
    "        results[-1] += [[]]\n",
    "        for k in range(ns_eval_samples[j]):\n",
    "            indices = np.random.choice(X.shape[0], ns_samples[j])\n",
    "            results[-1][-1] += [ learn(models[i], X[indices], Y[indices], scoring_funcs) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t<class 'sklearn.ensemble.gradient_boosting.GradientBoostingRegressor'>\n",
      "'mean_squared_error'\n",
      "[   [6.29, 6.263, 5.959, 4.572, 7.727, 10.636, 6.279],\n",
      "    [6.405, 6.787, 7.583, 4.75, 7.73, 11.082, 9.405],\n",
      "    [4.069, 4.526, 4.15, 3.682, 4.866, 7.448, 4.52],\n",
      "    [3.361, 3.339, 3.511, 2.97, 3.545, 6.163, 3.442],\n",
      "    [2.435, 2.548, 2.907, 2.385, 3.667, 4.474, 3.108]]\n",
      "'mean_absolute_error'\n",
      "[   [1.766, 1.775, 1.836, 1.617, 2.087, 2.528, 1.795],\n",
      "    [1.642, 1.758, 1.95, 1.456, 1.885, 2.28, 2.122],\n",
      "    [1.192, 1.342, 1.204, 1.106, 1.279, 1.705, 1.269],\n",
      "    [0.956, 0.971, 1.015, 0.977, 1.002, 1.415, 1.012],\n",
      "    [0.771, 0.802, 0.878, 0.809, 0.941, 1.105, 0.881]]\n",
      "'explained_variance_score'\n",
      "[   [-0.014, -0.081, 0.015, -0.017, -0.146, -0.159, 0.196],\n",
      "    [0.006, -0.193, -0.18, -0.088, -0.329, -0.129, -0.15],\n",
      "    [0.345, 0.134, 0.363, 0.141, 0.163, 0.193, 0.425],\n",
      "    [0.465, 0.417, 0.453, 0.356, 0.371, 0.365, 0.564],\n",
      "    [0.554, 0.51, 0.482, 0.457, 0.298, 0.532, 0.585]]\n",
      "'mean_squared_log_error'\n",
      "[   [0.458, 0.272, 0.361, 0.125, 0.265, 0.459, 0.502],\n",
      "    [0.343, 0.235, 0.34, 0.127, 0.282, 0.459, 0.545],\n",
      "    [0.266, 0.177, 0.242, 0.101, 0.197, 0.322, 0.305],\n",
      "    [0.206, 0.136, 0.189, 0.08, 0.139, 0.28, 0.24],\n",
      "    [0.149, 0.103, 0.151, 0.059, 0.145, 0.175, 0.189]]\n",
      "'r2_score'\n",
      "[   [-0.059, -0.117, -0.023, -0.051, -0.177, -0.191, 0.156],\n",
      "    [-0.013, -0.209, -0.194, -0.116, -0.337, -0.146, -0.165],\n",
      "    [0.336, 0.118, 0.354, 0.137, 0.16, 0.185, 0.419],\n",
      "    [0.459, 0.409, 0.45, 0.349, 0.365, 0.357, 0.561],\n",
      "    [0.551, 0.503, 0.478, 0.45, 0.284, 0.524, 0.582]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(models)):\n",
    "    print(\"\\t\" + str(type(models[i].estimator)).replace('\\n', ' '))\n",
    "    res = [[np.mean([results[i][j][k][1][l]\n",
    "                          for k in range(ns_eval_samples[j])], axis=0)\n",
    "                          for j in range(len(ns_samples))]\n",
    "                          for l in range(len(scoring_funcs))]\n",
    "    for l in range(len(scoring_funcs)):\n",
    "          pr(scoring_funcs[l].__name__)\n",
    "          pr([[float(\"{:,}\".format(round(r_, 3))) for r_ in list(r)] for r in res[l]])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t<class 'sklearn.ensemble.gradient_boosting.GradientBoostingRegressor'>\n",
      "'mean_squared_error: [ 6.818, 7.678, 4.752, 3.761, 3.075 ]'\n",
      "'mean_absolute_error: [ 1.915, 1.87, 1.3, 1.05, 0.884 ]'\n",
      "'explained_variance_score: [ -0.029, -0.152, 0.252, 0.427, 0.488 ]'\n",
      "'mean_squared_log_error: [ 0.349, 0.333, 0.23, 0.181, 0.139 ]'\n",
      "'r2_score: [ -0.066, -0.169, 0.244, 0.422, 0.482 ]'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(models)):\n",
    "    print(\"\\t\" + str(type(models[i].estimator)).replace('\\n', ' '))\n",
    "    res = [[round(np.mean([np.mean(results[i][j][k][1][l])\n",
    "                          for k in range(ns_eval_samples[j])]), 3)\n",
    "                          for j in range(len(ns_samples))]\n",
    "                          for l in range(len(scoring_funcs))]\n",
    "    for l in range(len(scoring_funcs)):\n",
    "        pr(scoring_funcs[l].__name__ + \": \" + \\\n",
    "          \"[ \" + ''.join([\"{:,}\".format(float(r)) + \", \" for r in res[l]])[:-2] + \" ]\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: 'bounces'\n",
      "Prediction: [1.0, 5.0, 6.0, 6.0, 8.0, 6.5, 5.75, 4.5]\n",
      "Actual: [ 1.    6.5   6.    8.5   9.    9.5   3.7   8.75]\n"
     ]
    }
   ],
   "source": [
    "print(\"Word: '\" + df.index[11] + \"'\")\n",
    "print(\"Prediction: \" + str([round(y, 3) for y in results[0][-1][0][0][11]]))\n",
    "print(\"Actual: \" + str(Y[11]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.,  3.])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([np.array([1,2]), np.array([3,4])], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
