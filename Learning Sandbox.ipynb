{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import inspect\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import *\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import *\n",
    "\n",
    "from Constants import *\n",
    "from Utils import *\n",
    "from Dataset import *\n",
    "from WordRepLibrary import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(sklearn.tree.tree.DecisionTreeClassifier,\n",
       " sklearn.tree.tree.BaseDecisionTree,\n",
       " abc.NewBase,\n",
       " sklearn.base.BaseEstimator,\n",
       " sklearn.base.ClassifierMixin,\n",
       " object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inspect.getmro(DecisionTreeClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = Dataset(combined_csv)\n",
    "df = dataset.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data(dataframe, x_lab, y_lab):\n",
    "    return np.array(dataframe[x_lab]), np.array(dataframe[y_lab])\n",
    "\n",
    "def learn(model, X, Y, scorers):\n",
    "    Y_pr = cross_val_predict(model, X, Y, cv=10)\n",
    "    errs = [scorer(Y, Y_pr, multioutput='raw_values') for scorer in scorers]\n",
    "#     errs = [scorer(Y, Y_pr, multioutput='uniform_average') for scorer in scorers]\n",
    "    return Y_pr, errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define Y values to learn\n",
    "Y_labels = Y_labels_default[1:] # All except 'inc', which is binary\n",
    "# Y_labels = Y_labels_default\n",
    "# Y_labels = ['dif', 'nrd', 'skt'] # Sketchability\n",
    "# Y_labels = ['dif', 'nrd', 'skt', 'vis'] # Visuality\n",
    "# Y_labels = ['vis', 'phy', 'obj'] # Physicality\n",
    "\n",
    "# Define X values to learn from\n",
    "X_labels = X_labels_default\n",
    "\n",
    "# Define models to evaluate\n",
    "models = [\n",
    "    MultiOutputRegressor(GradientBoostingRegressor()),\n",
    "]\n",
    "\n",
    "# Define scoring functions\n",
    "scoring_funcs = [\n",
    "    mean_absolute_error,\n",
    "    r2_score\n",
    "#     mean_squared_error,\n",
    "#     mean_squared_log_error,\n",
    "#     explained_variance_score,\n",
    "]\n",
    "\n",
    "# Train Multi-task models on interval_size-sample increments of data, up to the whole dataset\n",
    "interval_size = 10\n",
    "ns_samples = np.arange(0, df.shape[0], interval_size)[1:]\n",
    "\n",
    "# Take ns_eval_samples samples of random x for each increment, to get accurate results at low n\n",
    "ns_eval_samples = [10] * len(ns_samples)\n",
    "\n",
    "# Load data\n",
    "X, Y = get_data(df, X_labels, Y_labels)\n",
    "\n",
    "results = []\n",
    "for i in range(len(models)):\n",
    "    results += [[]]\n",
    "    for j in range(len(ns_samples)):\n",
    "        results[-1] += [[]]\n",
    "        for k in range(ns_eval_samples[j]):\n",
    "            indices = np.random.choice(X.shape[0], ns_samples[j])\n",
    "            results[-1][-1] += [ learn(models[i], X[indices], Y[indices], scoring_funcs) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t<class 'sklearn.ensemble.gradient_boosting.GradientBoostingRegressor'>\n",
      "'mean_absolute_error'\n",
      "[   [1.772, 1.659, 1.935, 1.644, 1.963, 2.113, 2.169],\n",
      "    [1.854, 1.728, 2.166, 1.687, 1.689, 2.413, 2.224],\n",
      "    [1.389, 1.323, 1.44, 1.184, 1.565, 1.935, 1.476],\n",
      "    [1.063, 0.929, 1.071, 0.933, 1.088, 1.401, 1.119],\n",
      "    [0.792, 0.794, 0.916, 0.839, 0.876, 1.118, 0.802]]\n",
      "'r2_score'\n",
      "[   [-0.019, -0.114, -0.019, -0.289, -0.364, -0.033, -0.077],\n",
      "    [-0.316, -0.124, -0.433, -0.202, -0.052, -0.149, -0.307],\n",
      "    [0.253, 0.176, 0.222, 0.243, 0.011, 0.076, 0.299],\n",
      "    [0.314, 0.446, 0.376, 0.385, 0.307, 0.326, 0.446],\n",
      "    [0.574, 0.551, 0.532, 0.374, 0.461, 0.545, 0.684]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(models)):\n",
    "    print(\"\\t\" + str(type(models[i].estimator)).replace('\\n', ' '))\n",
    "    res = [[np.mean([results[i][j][k][1][l]\n",
    "                          for k in range(ns_eval_samples[j])], axis=0)\n",
    "                          for j in range(len(ns_samples))]\n",
    "                          for l in range(len(scoring_funcs))]\n",
    "    for l in range(len(scoring_funcs)):\n",
    "          pr(scoring_funcs[l].__name__)\n",
    "          pr([[float(\"{:,}\".format(round(r_, 3))) for r_ in list(r)] for r in res[l]])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t<class 'sklearn.ensemble.gradient_boosting.GradientBoostingRegressor'>\n",
      "'mean_absolute_error: [ 1.894, 1.966, 1.473, 1.086, 0.877 ]'\n",
      "'r2_score: [ -0.131, -0.226, 0.183, 0.372, 0.532 ]'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(models)):\n",
    "    print(\"\\t\" + str(type(models[i].estimator)).replace('\\n', ' '))\n",
    "    res = [[round(np.mean([np.mean(results[i][j][k][1][l])\n",
    "                          for k in range(ns_eval_samples[j])]), 3)\n",
    "                          for j in range(len(ns_samples))]\n",
    "                          for l in range(len(scoring_funcs))]\n",
    "    for l in range(len(scoring_funcs)):\n",
    "        pr(scoring_funcs[l].__name__ + \": \" + \\\n",
    "          \"[ \" + ''.join([\"{:,}\".format(float(r)) + \", \" for r in res[l]])[:-2] + \" ]\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_pred = 100\n",
    "library = WordRepLibrary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: 'bounces'\n",
      "Prediction: [2.0339999999999998, 6.9260000000000002, 3.774, 3.343, 6.6349999999999998, 8.5410000000000004, 2.1179999999999999]\n",
      "Actual: [ 6.5   6.    8.5   9.    9.5   3.7   8.75]\n"
     ]
    }
   ],
   "source": [
    "print(\"Word: '\" + df.index[11] + \"'\")\n",
    "print(\"Prediction: \" + str([round(y, 3) for y in results[0][-1][0][0][11]]))\n",
    "print(\"Actual: \" + str(Y[11]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
