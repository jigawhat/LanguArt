{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Fonz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import *\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import *\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "from Constants import *\n",
    "from Utils import *\n",
    "from Dataset import *\n",
    "from DataRequests import *\n",
    "from WordRepLibrary import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(combined_csv)\n",
    "df = dataset.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data(dataframe, x_lab, y_lab):\n",
    "    return np.array(dataframe[x_lab]), np.array(dataframe[y_lab])\n",
    "\n",
    "def learn(model, X, Y, scorers):\n",
    "    Y_pr = cross_val_predict(model, X, Y, cv=10)\n",
    "    errs = [scorer(Y, Y_pr, multioutput='raw_values') for scorer in scorers]\n",
    "    return Y_pr, errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Y values to learn\n",
    "Y_labels = Y_labels_default[1:] # All except 'inc', which is binary\n",
    "# Y_labels = Y_labels_default\n",
    "# Y_labels = ['dif', 'nrd', 'skt'] # Sketchability\n",
    "# Y_labels = ['dif', 'nrd', 'skt', 'vis'] # Visuality\n",
    "# Y_labels = ['vis', 'phy', 'obj'] # Physicality\n",
    "\n",
    "# Define X values to learn from\n",
    "X_labels = X_labels_default\n",
    "\n",
    "# Define models to evaluate\n",
    "models = [\n",
    "    Pipeline(steps=[\n",
    "        (\"scale\", RobustScaler()),\n",
    "        (\"model\", MultiOutputRegressor(GradientBoostingRegressor())),\n",
    "    ]),\n",
    "]\n",
    "\n",
    "# Define scoring functions\n",
    "scoring_funcs = [\n",
    "    mean_absolute_error,\n",
    "    r2_score\n",
    "#     mean_squared_error,\n",
    "#     mean_squared_log_error,\n",
    "#     explained_variance_score,\n",
    "]\n",
    "\n",
    "# Train Multi-task models on interval_size-sample increments of data, up to the whole dataset\n",
    "interval_size = 18\n",
    "ns_samples = np.arange(0, df.shape[0], interval_size)[1:]\n",
    "\n",
    "# Take ns_eval_samples samples of random x for each increment, to get accurate results at low n\n",
    "ns_eval_samples = [10] * len(ns_samples)\n",
    "\n",
    "# Load data\n",
    "X, Y = get_data(df, X_labels, Y_labels)\n",
    "\n",
    "# For debug: convert x data into random numbers\n",
    "# X = np.random.random(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform cross validation\n",
    "results = []\n",
    "for i in range(len(models)):\n",
    "    results += [[]]\n",
    "    for j in range(len(ns_samples)):\n",
    "        results[-1] += [[]]\n",
    "        for k in range(ns_eval_samples[j]):\n",
    "            indices = np.random.choice(X.shape[0], ns_samples[j])\n",
    "            results[-1][-1] += [ learn(models[i], X[indices], Y[indices], scoring_funcs) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t<class 'sklearn.ensemble.gradient_boosting.GradientBoostingRegressor'>\n",
      "'mean_absolute_error'\n",
      "[   [1.92, 1.793, 1.914, 1.729, 1.637, 2.643, 1.836],\n",
      "    [1.237, 1.122, 1.213, 1.073, 1.268, 1.693, 1.408]]\n",
      "'r2_score'\n",
      "[   [-0.12, -0.195, -0.23, -0.492, -0.311, -0.392, 0.104],\n",
      "    [0.185, 0.214, 0.351, 0.203, 0.193, 0.164, 0.263]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print errors\n",
    "for i in range(len(models)):\n",
    "    print(\"\\t\" + str(type(models[i].steps[-1][1].estimator)).replace('\\n', ' '))\n",
    "    res = [[np.mean([results[i][j][k][1][l]\n",
    "                          for k in range(ns_eval_samples[j])], axis=0)\n",
    "                          for j in range(len(ns_samples))]\n",
    "                          for l in range(len(scoring_funcs))]\n",
    "    for l in range(len(scoring_funcs)):\n",
    "          pr(scoring_funcs[l].__name__)\n",
    "          pr([format_numlist(r, 3) for r in res[l]])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t<class 'sklearn.ensemble.gradient_boosting.GradientBoostingRegressor'>\n",
      "'mean_absolute_error: [1.925, 1.288]'\n",
      "'r2_score: [-0.234, 0.225]'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print average errors\n",
    "for i in range(len(models)):\n",
    "    print(\"\\t\" + str(type(models[i].steps[-1][1].estimator)).replace('\\n', ' '))\n",
    "    res = [[round(np.mean([np.mean(results[i][j][k][1][l])\n",
    "                          for k in range(ns_eval_samples[j])]), 3)\n",
    "                          for j in range(len(ns_samples))]\n",
    "                          for l in range(len(scoring_funcs))]\n",
    "    for l in range(len(scoring_funcs)):\n",
    "        pr(scoring_funcs[l].__name__ + \": \" + \\\n",
    "           str(format_numlist(res[l], 3)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Inspect errors\n",
    "print(\"Word: '\" + df.index[11] + \"'\")\n",
    "print(\"Prediction: \" + str([round(y, 3) for y in results[0][-1][0][0][11]]))\n",
    "print(\"Actual: \" + str(Y[11]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading ngram counts database... 5899064 entries\n",
      "Loading ngram counts database took 4.8438801765441895 seconds.\n",
      "Loading word representation library 'glove.42B.300d.txt'\n",
      "Loading word representation library took 97.02606701850891 seconds.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load data for new word prediction\n",
    "ngrams_db = load_ngram_counts()             # Load ngram counts database\n",
    "wrep_lib = WordRepLibrary(lib_paths[-1])    # Load word representation database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ['dif', 'nrd', 'skt', 'vis', 'phy', 'obj', 'com']\n",
      "alaskans: [3.73, 4.321, 1.941, 5.43, 5.848, 8.015, 1.988]\n",
      "hyperbilirubinemia: [1.686, 3.164, 3.995, 6.919, 6.753, 2.726, 1.19]\n",
      "allies: [4.887, 5.133, 5.439, 6.328, 8.146, 6.931, 5.532]\n",
      "loggings: [1.903, 4.138, 4.321, 4.901, 4.741, 1.513, 1.387]\n",
      "astute: [2.87, 6.658, 3.775, 7.071, 5.445, 6.764, 3.471]\n",
      "faster: [5.064, 4.403, 7.141, 7.123, 7.624, 2.671, 6.413]\n",
      "plowed: [6.461, 6.285, 6.452, 6.362, 8.309, 7.31, 5.935]\n",
      "ancistrodon: [1.419, 3.095, 1.518, 6.468, 8.181, 5.347, 0.951]\n",
      "stoppers: [5.706, 5.543, 5.084, 5.898, 6.923, 4.983, 4.457]\n",
      "eatings: [1.899, 3.204, 3.356, 6.023, 8.035, 3.211, 2.119]\n",
      "communion: [4.67, 2.661, 4.983, 3.734, 6.433, 2.117, 6.073]\n",
      "prevent: [5.875, 5.216, 5.758, 7.711, 8.276, 3.422, 5.141]\n",
      "spotless: [4.827, 5.954, 6.728, 4.075, 5.043, 8.334, 4.703]\n",
      "uscb: [1.792, 3.314, 4.26, 6.674, 6.474, 5.412, 1.114]\n",
      "firethorn: [3.08, 5.301, 2.02, 6.057, 7.791, 7.92, 1.092]\n",
      "surmounting: [2.057, 3.25, 1.886, 5.034, 6.696, 5.025, 0.617]\n",
      "architecturally: [3.004, 4.813, 2.511, 4.995, 4.227, 3.397, 2.701]\n",
      "sanative: [3.045, 4.022, 3.363, 5.036, 6.191, 2.671, 1.361]\n",
      "stachys: [2.349, 3.562, 4.34, 5.069, 4.71, 3.362, 2.403]\n",
      "downstrokes: [1.345, 2.453, 3.557, 4.217, 3.413, 3.035, 1.806]\n",
      "diocesans: [1.323, 3.507, 1.633, 3.912, 6.562, 4.624, 0.931]\n",
      "desisting: [2.867, 4.578, 2.348, 5.878, 6.676, 2.615, 1.186]\n",
      "porzana: [2.131, 3.503, 3.4, 4.986, 5.463, 3.477, 1.441]\n",
      "statesmans: [0.965, 3.163, 3.182, 6.346, 8.07, 1.642, 1.875]\n",
      "saucer: [7.115, 7.136, 4.82, 5.502, 6.025, 7.607, 5.611]\n",
      "excavator: [5.155, 6.72, 6.382, 5.819, 6.035, 8.23, 3.056]\n",
      "hothouse: [1.432, 2.534, 2.59, 6.793, 7.617, 4.235, 2.081]\n",
      "pyramides: [2.683, 4.015, 2.109, 6.399, 8.35, 1.726, 1.101]\n",
      "bedchambers: [2.024, 3.581, 1.906, 4.881, 4.685, 1.736, 1.899]\n",
      "averts: [1.507, 2.168, 2.519, 5.382, 3.953, 3.417, 1.531]\n",
      "chart: [5.623, 5.807, 5.577, 6.104, 3.66, 6.959, 4.962]\n",
      "brahui: [2.087, 2.614, 3.859, 5.126, 5.838, 4.609, 2.781]\n",
      "citrates: [1.658, 4.759, 3.688, 5.014, 6.473, 4.877, 0.808]\n",
      "shanked: [2.7, 4.828, 3.56, 4.851, 6.228, 3.395, 1.187]\n",
      "yessssss: [2.521, 3.848, 2.012, 5.184, 1.833, 4.329, 0.924]\n",
      "captioning: [2.879, 5.519, 4.782, 7.487, 7.853, 7.278, 3.499]\n",
      "pallette: [2.012, 3.714, 2.435, 6.205, 7.096, 2.355, 1.52]\n",
      "patchworks: [1.701, 3.924, 3.808, 4.772, 6.291, 1.713, 2.32]\n",
      "shading: [4.419, 4.224, 7.926, 7.01, 8.065, 5.588, 4.366]\n",
      "brandts: [1.374, 3.811, 1.836, 4.505, 4.202, 2.444, 1.689]\n",
      "oktoberfest: [5.937, 4.641, 5.786, 6.579, 6.304, 7.491, 4.844]\n",
      "etiolation: [1.656, 3.514, 1.71, 6.159, 7.923, 1.829, 1.386]\n",
      "harboring: [1.193, 3.384, 4.193, 5.333, 3.42, 2.916, 2.688]\n",
      "grumblers: [1.776, 4.461, 4.342, 5.716, 6.251, 2.899, 1.327]\n",
      "boneheaded: [2.29, 3.488, 4.121, 6.198, 3.9, 3.688, 2.102]\n",
      "drugs: [4.74, 3.907, 5.359, 4.742, 4.853, 3.837, 5.753]\n",
      "enemys: [3.123, 6.986, 2.818, 5.846, 8.637, 7.135, 2.338]\n",
      "teleosts: [0.965, 4.222, 3.889, 4.243, 4.011, 2.163, 0.984]\n",
      "pretensions: [1.406, 2.933, 1.68, 5.226, 5.012, 1.777, 1.756]\n",
      "pacifying: [1.497, 3.87, 3.22, 4.585, 3.727, 1.989, 1.299]\n",
      "titillate: [2.519, 3.227, 2.222, 5.8, 6.263, 2.353, 1.94]\n",
      "blowball: [1.868, 2.591, 2.153, 5.551, 6.203, 2.284, 1.785]\n",
      "haft: [1.65, 3.72, 2.029, 6.773, 8.417, 5.086, 0.923]\n",
      "thoreaus: [1.206, 3.305, 1.824, 3.931, 5.197, 1.453, 1.739]\n",
      "ordinands: [2.519, 4.437, 2.679, 5.074, 4.015, 2.973, 1.706]\n",
      "follows: [2.215, 3.246, 4.866, 3.705, 3.968, 2.92, 6.858]\n",
      "squarish: [2.109, 4.257, 1.739, 5.285, 6.345, 7.761, 2.348]\n",
      "bazookas: [3.592, 5.923, 4.2, 6.12, 8.204, 7.613, 3.405]\n",
      "teredo: [2.358, 2.222, 1.835, 6.842, 7.084, 4.75, 2.593]\n",
      "unfit: [3.624, 6.621, 4.797, 5.378, 6.021, 7.961, 4.35]\n",
      "snatcher: [4.95, 4.585, 7.687, 7.415, 8.28, 2.748, 3.784]\n",
      "skuas: [2.028, 4.397, 2.977, 5.293, 7.135, 4.041, 2.246]\n",
      "terce: [1.775, 4.493, 3.551, 4.281, 4.428, 4.229, 1.009]\n",
      "pulpit: [3.432, 2.623, 5.361, 5.016, 5.854, 3.208, 5.495]\n",
      "peaceful: [4.508, 2.697, 4.475, 5.537, 3.745, 3.282, 5.627]\n",
      "numerology: [4.57, 4.017, 5.483, 7.487, 7.952, 2.575, 6.454]\n",
      "floppy: [3.441, 6.732, 6.413, 4.873, 7.38, 6.003, 6.15]\n",
      "huggins: [2.546, 2.685, 7.956, 6.764, 7.438, 2.201, 3.991]\n",
      "undeserving: [3.027, 4.843, 4.059, 5.784, 6.562, 2.5, 2.996]\n",
      "saddled: [5.558, 5.872, 7.121, 5.776, 4.363, 7.033, 4.113]\n",
      "paramedical: [2.203, 4.106, 1.7, 4.969, 6.624, 2.919, 2.453]\n",
      "diesel: [4.198, 3.007, 6.009, 5.734, 6.706, 5.974, 5.291]\n",
      "homogeneities: [1.295, 3.479, 2.842, 5.13, 5.22, 4.914, 0.945]\n",
      "ascent: [3.28, 3.235, 4.562, 4.641, 3.144, 3.43, 4.987]\n",
      "squinch: [1.578, 3.37, 2.002, 6.24, 4.835, 2.38, 1.075]\n",
      "waxberry: [2.063, 4.279, 4.18, 4.388, 5.897, 3.181, 1.739]\n",
      "nephrology: [3.063, 4.093, 4.32, 4.564, 5.826, 2.931, 3.032]\n",
      "shape: [5.104, 3.695, 7.791, 4.519, 8.15, 3.969, 8.076]\n",
      "fictionalised: [1.869, 3.228, 1.2, 6.328, 6.794, 4.414, 1.961]\n",
      "albumins: [1.868, 3.406, 3.814, 4.479, 6.264, 3.207, 0.468]\n",
      "succors: [1.987, 4.042, 3.46, 5.524, 5.904, 2.255, 1.818]\n",
      "blithered: [2.136, 4.045, 2.795, 6.601, 7.692, 2.634, 1.44]\n",
      "solidifies: [2.541, 2.677, 3.844, 5.032, 1.95, 2.729, 2.669]\n",
      "sneads: [3.682, 5.728, 5.348, 7.361, 8.081, 6.514, 4.278]\n",
      "everest: [4.321, 6.497, 5.263, 4.496, 5.01, 6.663, 5.638]\n",
      "exceedingly: [2.806, 5.27, 4.892, 4.561, 3.741, 2.883, 2.245]\n",
      "rout: [4.994, 2.789, 4.589, 6.247, 4.459, 3.701, 4.977]\n",
      "enrich: [3.231, 2.855, 2.448, 6.262, 7.509, 4.349, 3.278]\n",
      "closedown: [2.399, 3.865, 3.928, 3.785, 4.792, 4.941, 1.543]\n",
      "featherbrained: [1.784, 3.119, 3.485, 5.535, 5.794, 4.339, 1.913]\n",
      "riemannian: [2.127, 3.452, 3.471, 3.912, 5.819, 5.741, 2.091]\n",
      "doctorow: [2.932, 4.561, 5.62, 5.722, 6.561, 2.33, 3.474]\n",
      "perm: [6.013, 4.125, 5.168, 3.619, 6.611, 5.064, 5.973]\n",
      "fruitless: [2.865, 4.32, 2.799, 5.867, 8.006, 2.696, 2.346]\n",
      "colonel: [3.805, 6.574, 5.967, 4.54, 3.928, 7.381, 6.018]\n",
      "roadsters: [3.449, 4.844, 6.591, 6.381, 8.239, 8.293, 3.434]\n",
      "brama: [2.833, 5.3, 2.585, 5.633, 6.781, 7.018, 1.956]\n",
      "enact: [1.432, 1.685, 3.303, 5.301, 5.79, 2.88, 2.059]\n",
      "coppered: [0.498, 4.284, 3.562, 4.498, 7.332, 2.191, 1.857]\n",
      "junes: [4.064, 6.193, 2.72, 7.254, 8.938, 7.814, 2.097]\n"
     ]
    }
   ],
   "source": [
    "# Predict for some random new words\n",
    "n_pred = 100\n",
    "i_seen = map(int, list(df[\"lib_i\"]))\n",
    "model = models[-1]\n",
    "model.fit(X, Y)\n",
    "print(\"         \", Y_labels)\n",
    "for i in range(n_pred):\n",
    "    word, word_i, x = wrep_lib.get_new_word(i_seen)\n",
    "    while word not in ngrams_db.index or not valid_word(word, verbose=False):\n",
    "        word, word_i, x = wrep_lib.get_new_word()\n",
    "    x += list(ngrams_db.loc[word]) + [ google_search_count(word) ]\n",
    "    y_pred = model.predict(np.atleast_2d(x))\n",
    "    print(word + \": \" + str(format_numlist(y_pred[0], 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
