{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import inspect\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import *\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import *\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "from Constants import *\n",
    "from Utils import *\n",
    "from Dataset import *\n",
    "from DataRequests import *\n",
    "from WordRepLibrary import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(sklearn.tree.tree.DecisionTreeClassifier,\n",
       " sklearn.tree.tree.BaseDecisionTree,\n",
       " abc.NewBase,\n",
       " sklearn.base.BaseEstimator,\n",
       " sklearn.base.ClassifierMixin,\n",
       " object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inspect.getmro(DecisionTreeClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = Dataset(combined_csv)\n",
    "df = dataset.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data(dataframe, x_lab, y_lab):\n",
    "    return np.array(dataframe[x_lab]), np.array(dataframe[y_lab])\n",
    "\n",
    "def learn(model, X, Y, scorers):\n",
    "    Y_pr = cross_val_predict(model, X, Y, cv=10)\n",
    "    errs = [scorer(Y, Y_pr, multioutput='raw_values') for scorer in scorers]\n",
    "    return Y_pr, errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define Y values to learn\n",
    "Y_labels = Y_labels_default[1:] # All except 'inc', which is binary\n",
    "# Y_labels = Y_labels_default\n",
    "# Y_labels = ['dif', 'nrd', 'skt'] # Sketchability\n",
    "# Y_labels = ['dif', 'nrd', 'skt', 'vis'] # Visuality\n",
    "# Y_labels = ['vis', 'phy', 'obj'] # Physicality\n",
    "\n",
    "# Define X values to learn from\n",
    "X_labels = X_labels_default\n",
    "\n",
    "# Define models to evaluate\n",
    "models = [\n",
    "    Pipeline(steps=[\n",
    "        (\"scale\", RobustScaler()),\n",
    "        (\"model\", MultiOutputRegressor(GradientBoostingRegressor())),\n",
    "    ]),\n",
    "]\n",
    "\n",
    "# Define scoring functions\n",
    "scoring_funcs = [\n",
    "    mean_absolute_error,\n",
    "    r2_score\n",
    "#     mean_squared_error,\n",
    "#     mean_squared_log_error,\n",
    "#     explained_variance_score,\n",
    "]\n",
    "\n",
    "# Train Multi-task models on interval_size-sample increments of data, up to the whole dataset\n",
    "interval_size = 18\n",
    "ns_samples = np.arange(0, df.shape[0], interval_size)[1:]\n",
    "\n",
    "# Take ns_eval_samples samples of random x for each increment, to get accurate results at low n\n",
    "ns_eval_samples = [10] * len(ns_samples)\n",
    "\n",
    "# Load data\n",
    "X, Y = get_data(df, X_labels, Y_labels)\n",
    "\n",
    "# For debug: convert x data into random numbers\n",
    "X = np.random.random(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Perform cross validation\n",
    "results = []\n",
    "for i in range(len(models)):\n",
    "    results += [[]]\n",
    "    for j in range(len(ns_samples)):\n",
    "        results[-1] += [[]]\n",
    "        for k in range(ns_eval_samples[j]):\n",
    "            indices = np.random.choice(X.shape[0], ns_samples[j])\n",
    "            results[-1][-1] += [ learn(models[i], X[indices], Y[indices], scoring_funcs) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t<class 'sklearn.ensemble.gradient_boosting.GradientBoostingRegressor'>\n",
      "'mean_absolute_error'\n",
      "[   [1.772, 1.659, 1.935, 1.644, 1.963, 2.113, 2.169],\n",
      "    [1.854, 1.728, 2.166, 1.687, 1.689, 2.413, 2.224],\n",
      "    [1.389, 1.323, 1.44, 1.184, 1.565, 1.935, 1.476],\n",
      "    [1.063, 0.929, 1.071, 0.933, 1.088, 1.401, 1.119],\n",
      "    [0.792, 0.794, 0.916, 0.839, 0.876, 1.118, 0.802]]\n",
      "'r2_score'\n",
      "[   [-0.019, -0.114, -0.019, -0.289, -0.364, -0.033, -0.077],\n",
      "    [-0.316, -0.124, -0.433, -0.202, -0.052, -0.149, -0.307],\n",
      "    [0.253, 0.176, 0.222, 0.243, 0.011, 0.076, 0.299],\n",
      "    [0.314, 0.446, 0.376, 0.385, 0.307, 0.326, 0.446],\n",
      "    [0.574, 0.551, 0.532, 0.374, 0.461, 0.545, 0.684]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print errors\n",
    "for i in range(len(models)):\n",
    "    print(\"\\t\" + str(type(models[i].estimator)).replace('\\n', ' '))\n",
    "    res = [[np.mean([results[i][j][k][1][l]\n",
    "                          for k in range(ns_eval_samples[j])], axis=0)\n",
    "                          for j in range(len(ns_samples))]\n",
    "                          for l in range(len(scoring_funcs))]\n",
    "    for l in range(len(scoring_funcs)):\n",
    "          pr(scoring_funcs[l].__name__)\n",
    "          pr([[float(\"{:,}\".format(round(r_, 3))) for r_ in list(r)] for r in res[l]])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t<class 'sklearn.ensemble.gradient_boosting.GradientBoostingRegressor'>\n",
      "'mean_absolute_error: [ 1.894, 1.966, 1.473, 1.086, 0.877 ]'\n",
      "'r2_score: [ -0.131, -0.226, 0.183, 0.372, 0.532 ]'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print average errors\n",
    "for i in range(len(models)):\n",
    "    print(\"\\t\" + str(type(models[i].estimator)).replace('\\n', ' '))\n",
    "    res = [[round(np.mean([np.mean(results[i][j][k][1][l])\n",
    "                          for k in range(ns_eval_samples[j])]), 3)\n",
    "                          for j in range(len(ns_samples))]\n",
    "                          for l in range(len(scoring_funcs))]\n",
    "    for l in range(len(scoring_funcs)):\n",
    "        pr(scoring_funcs[l].__name__ + \": \" + \\\n",
    "          \"[ \" + ''.join([\"{:,}\".format(float(r)) + \", \" for r in res[l]])[:-2] + \" ]\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading ngram counts database... 5899064 entries\n",
      "Loading ngram counts database took 12.817402124404907 seconds.\n",
      "Loading word representation library 'glove.42B.300d.txt'\n",
      "Loading word representation library took 501.7303628921509 seconds.\n",
      "\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "ix is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-ce1a57ff2ded>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_new_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngrams_db\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0mgoogle_search_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ix is not iterable'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: ix is not iterable"
     ]
    }
   ],
   "source": [
    "# Predict for some random words\n",
    "n_pred = 100\n",
    "ngrams_db = load_ngram_counts()            # Load ngram counts database\n",
    "library = WordRepLibrary(lib_paths[-1])    # Load word representation database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pandas.core.indexing._LocIndexer object at 0x111aff358>\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "ix is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-1e5b57c65e05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_new_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngrams_db\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngrams_db\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0mgoogle_search_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ix is not iterable'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: ix is not iterable"
     ]
    }
   ],
   "source": [
    "for i in range(n_pred):\n",
    "    word, word_i, x = library.get_new_word()\n",
    "    print((ngrams_db.loc(word)))\n",
    "    x += list(ngrams_db.loc(word)) + [ google_search_count(word) ]\n",
    "    print(len(x), X.shape)\n",
    "    sys.exit()\n",
    "#     y_pred = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: 'bounces'\n",
      "Prediction: [2.0339999999999998, 6.9260000000000002, 3.774, 3.343, 6.6349999999999998, 8.5410000000000004, 2.1179999999999999]\n",
      "Actual: [ 6.5   6.    8.5   9.    9.5   3.7   8.75]\n"
     ]
    }
   ],
   "source": [
    "print(\"Word: '\" + df.index[11] + \"'\")\n",
    "print(\"Prediction: \" + str([round(y, 3) for y in results[0][-1][0][0][11]]))\n",
    "print(\"Actual: \" + str(Y[11]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-6602b2c53833>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'models' is not defined"
     ]
    }
   ],
   "source": [
    "models[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ns_samples = np.arange(0, df.shape[0], 18)[1:]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
